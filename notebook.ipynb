{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Multi-dimensional arrays and datasets\n",
    "import xarray as xr\n",
    "\n",
    "# Geospatial raster data handling\n",
    "import rioxarray as rxr\n",
    "\n",
    "# Geospatial data analysis\n",
    "import geopandas as gpd\n",
    "\n",
    "# Geospatial operations\n",
    "import rasterio\n",
    "from rasterio import windows  \n",
    "from rasterio import features  \n",
    "from rasterio import warp\n",
    "from rasterio.warp import transform_bounds \n",
    "from rasterio.windows import from_bounds \n",
    "\n",
    "import pyogrio\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image\n",
    "\n",
    "# Coordinate transformations\n",
    "from pyproj import Proj, Transformer, CRS\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Feature Importance\n",
    "import shap \n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor    \n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "# from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "import optuna\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "\n",
    "# Others\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('UHI_data.csv')\n",
    "bronx_df = pd.read_excel('NY_Mesonet_Weather.xlsx', sheet_name='Bronx')\n",
    "manhattan_df = pd.read_excel('NY_Mesonet_Weather.xlsx', sheet_name='Manhattan')\n",
    "submission = pd.read_csv('Validation_with_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_train_data(df, bronx, manhattan, tolerance=0.01, bronx_lat=40.87248,\n",
    "               bronx_lon=-73.89352, manhattan_lat=40.76754, manhattan_lon=-73.96449):\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "    bronx['Date / Time'] = pd.to_datetime(bronx['Date / Time'])\n",
    "    manhattan['Date / Time'] = pd.to_datetime(manhattan['Date / Time'])\n",
    "\n",
    "    bronx.rename(columns={'Date / Time': 'datetime'}, inplace=True)\n",
    "    manhattan.rename(columns={'Date / Time': 'datetime'}, inplace=True)\n",
    "\n",
    "    # Filter CSV for Manhattan based on coordinate tolerance:\n",
    "    manhattan_csv = df[\n",
    "        (df['Latitude'].between(manhattan_lat - tolerance, manhattan_lat + tolerance)) |\n",
    "        (df['Longitude'].between(manhattan_lon - tolerance, manhattan_lon + tolerance))\n",
    "    ]\n",
    "\n",
    "    bronx_csv = df[\n",
    "        (df['Latitude'].between(bronx_lat - tolerance, bronx_lat + tolerance)) |\n",
    "        (df['Longitude'].between(bronx_lon - tolerance, bronx_lon + tolerance))\n",
    "    ]\n",
    "\n",
    "    print(\"Manhattan CSV rows found:\", len(manhattan_csv))\n",
    "    print(\"Bronx CSV rows found:\", len(bronx_csv))\n",
    "\n",
    "    # Merge the temperature data from Excel with the corresponding CSV data based on datetime.\n",
    "    # For Manhattan:\n",
    "    merged_manhattan = pd.merge(manhattan_csv, manhattan, on='datetime', how='inner')\n",
    "    print(\"Merged Manhattan data:\")\n",
    "    print(merged_manhattan.head())\n",
    "\n",
    "    # For Bronx, if any rows are found; if not, consider a wider tolerance\n",
    "    if not bronx_csv.empty:\n",
    "        merged_bronx = pd.merge(bronx_csv, bronx, on='datetime', how='inner')\n",
    "        print(\"Merged Bronx data:\")\n",
    "        print(merged_bronx.head())\n",
    "    else:\n",
    "        print(\"No Bronx rows found in CSV with tolerance of Â±0.01. Consider increasing tolerance.\")\n",
    "\n",
    "    manhattan_lookup = merged_manhattan[['Longitude', 'Latitude',\n",
    "                                      'Air Temp at Surface [degC]',\n",
    "                                      'Relative Humidity [percent]',\n",
    "                                      'Avg Wind Speed [m/s]',\n",
    "                                      'Wind Direction [degrees]',\n",
    "                                      'Solar Flux [W/m^2]']]\n",
    "\n",
    "    bronx_lookup = merged_bronx[['Longitude', 'Latitude',\n",
    "                                'Air Temp at Surface [degC]',\n",
    "                                'Relative Humidity [percent]',\n",
    "                                'Avg Wind Speed [m/s]',\n",
    "                                'Wind Direction [degrees]',\n",
    "                                'Solar Flux [W/m^2]']]\n",
    "\n",
    "    # Combine (concatenate) the two lookup DataFrames into one.\n",
    "    lookup = pd.concat([manhattan_lookup, bronx_lookup])\n",
    "\n",
    "    # Now merge the main DataFrame (uhi) with the combined lookup DataFrame on the key columns.\n",
    "    df = pd.merge(df, lookup, on=['Longitude', 'Latitude'], how='left')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan CSV rows found: 247\n",
      "Bronx CSV rows found: 161\n",
      "Merged Manhattan data:\n",
      "   Longitude   Latitude            datetime  UHI Index     B01     B02  \\\n",
      "0 -73.982343  40.768468 2021-07-24 15:55:00   0.966339  1045.0  1104.0   \n",
      "1 -73.982388  40.768360 2021-07-24 15:55:00   0.966339  1045.0  1342.0   \n",
      "2 -73.982418  40.768285 2021-07-24 15:55:00   0.970667  1045.0  1108.0   \n",
      "3 -73.982428  40.768205 2021-07-24 15:55:00   0.970667  1045.0  1260.0   \n",
      "4 -73.982407  40.767880 2021-07-24 15:55:00   0.968503  1296.0   940.0   \n",
      "\n",
      "      B03     B04     B05     B06  ...     B8A     B11     B12        LST  \\\n",
      "0  1420.0  1378.0  1682.0  2171.0  ...  2506.0  1868.0  1518.0  36.753292   \n",
      "1  1564.0  1500.0  2004.0  2903.0  ...  3020.0  1806.0  1280.0  36.753292   \n",
      "2  1252.0  1290.0  1699.0  1999.0  ...  2169.0  1614.0  1351.0  36.753292   \n",
      "3  1280.0   998.0  1699.0  1999.0  ...  2169.0  1614.0  1351.0  36.305531   \n",
      "4   993.0   929.0  1880.0  2287.0  ...  2361.0  2135.0  1826.0  35.608255   \n",
      "\n",
      "   is_building  Air Temp at Surface [degC]  Relative Humidity [percent]  \\\n",
      "0            0                        26.8                         46.7   \n",
      "1            0                        26.8                         46.7   \n",
      "2            0                        26.8                         46.7   \n",
      "3            0                        26.8                         46.7   \n",
      "4            0                        26.8                         46.7   \n",
      "\n",
      "   Avg Wind Speed [m/s]  Wind Direction [degrees]  Solar Flux [W/m^2]  \n",
      "0                   3.4                       196                 605  \n",
      "1                   3.4                       196                 605  \n",
      "2                   3.4                       196                 605  \n",
      "3                   3.4                       196                 605  \n",
      "4                   3.4                       196                 605  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Merged Bronx data:\n",
      "   Longitude   Latitude            datetime  UHI Index     B01     B02  \\\n",
      "0 -73.893698  40.844500 2021-07-24 15:55:00   0.992905  1501.0  1306.0   \n",
      "1 -73.893788  40.844537 2021-07-24 15:55:00   0.992905  1501.0  2032.0   \n",
      "2 -73.893860  40.844570 2021-07-24 15:55:00   0.990741  1501.0  1260.0   \n",
      "3 -73.893913  40.844597 2021-07-24 15:55:00   0.990741  1501.0  1260.0   \n",
      "4 -73.893957  40.844605 2021-07-24 15:55:00   0.990741  1501.0   805.0   \n",
      "\n",
      "      B03     B04     B05     B06  ...     B8A     B11     B12        LST  \\\n",
      "0  1418.0  1892.0  3095.0  2881.0  ...  3191.0  3552.0  3092.0  35.680033   \n",
      "1  1858.0  2248.0  3258.0  3872.0  ...  3802.0  3694.0  3998.0  35.680033   \n",
      "2  1210.0  1836.0  3258.0  3872.0  ...  3802.0  3694.0  3998.0  35.594583   \n",
      "3  1210.0  1836.0  3258.0  3872.0  ...  3802.0  3694.0  3998.0  34.979339   \n",
      "4   844.0   816.0  2013.0  1737.0  ...  2064.0  2499.0  1941.0  34.979339   \n",
      "\n",
      "   is_building  Air Temp at Surface [degC]  Relative Humidity [percent]  \\\n",
      "0            0                        27.2                         47.3   \n",
      "1            0                        27.2                         47.3   \n",
      "2            0                        27.2                         47.3   \n",
      "3            0                        27.2                         47.3   \n",
      "4            0                        27.2                         47.3   \n",
      "\n",
      "   Avg Wind Speed [m/s]  Wind Direction [degrees]  Solar Flux [W/m^2]  \n",
      "0                   2.6                       165                 621  \n",
      "1                   2.6                       165                 621  \n",
      "2                   2.6                       165                 621  \n",
      "3                   2.6                       165                 621  \n",
      "4                   2.6                       165                 621  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "uhi = merge_train_data(df, bronx_df, manhattan_df, tolerance=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=10, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_cols = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', \n",
    "                'B07', 'B08', 'B8A', 'B11', 'B12']\n",
    "weather_cols = [\n",
    "    'Air Temp at Surface [degC]',\n",
    "    'Relative Humidity [percent]',\n",
    "    'Avg Wind Speed [m/s]',\n",
    "    'Wind Direction [degrees]',\n",
    "    'Solar Flux [W/m^2]'\n",
    "]\n",
    "\n",
    "coord_cols=['Longitude', 'Latitude']\n",
    "\n",
    "impute_cols = coord_cols + band_cols + weather_cols\n",
    "\n",
    "# Check that all required columns exist in uhi.\n",
    "missing_cols = [col for col in impute_cols if col not in uhi.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"The following columns are missing from the DataFrame: {missing_cols}\")\n",
    "\n",
    "# Create a copy of the relevant data for imputation.\n",
    "data_to_impute = uhi[impute_cols].copy()\n",
    "\n",
    "# Initialize the KNNImputer.\n",
    "imputer = KNNImputer(n_neighbors=10, weights='distance')\n",
    "\n",
    "# Fit and transform the data.\n",
    "imputed_array = imputer.fit_transform(data_to_impute)\n",
    "\n",
    "# The imputed_array has the same order as impute_cols.\n",
    "# Extract the imputed weather data columns. They are at the end of the array.\n",
    "weather_start_idx = len(coord_cols) + len(band_cols)\n",
    "imputed_weather = imputed_array[:, weather_start_idx:]\n",
    "\n",
    "uhi[weather_cols] = imputed_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weather_cols:\n",
    "    if col not in submission.columns:\n",
    "        submission[col] = np.nan\n",
    "\n",
    "test_for_impute = submission[impute_cols].copy()\n",
    "\n",
    "# Use the trained imputer to transform the test data.\n",
    "imputed_array = imputer.transform(test_for_impute)\n",
    "\n",
    "# The imputer was trained on data with columns in the order:\n",
    "#   coord_cols + band_cols + weather_cols.\n",
    "# Extract the imputed weather columns (the last len(weather_cols) columns).\n",
    "imputed_weather = imputed_array[:, -len(weather_cols):]\n",
    "\n",
    "# Update the test DataFrame's weather columns with the imputed values.\n",
    "submission[weather_cols] = imputed_weather\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y), and then into training and testing sets\n",
    "X = uhi.drop(columns=['Longitude','Latitude','datetime','UHI Index']).values\n",
    "y = uhi['UHI Index'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_xg(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "#         # 'tree_method': trial.suggest_categorical('tree_method', ['exact', 'approx', 'hist'])\n",
    "#     }\n",
    "    \n",
    "#     model = XGBRegressor(**params, random_state=42, tree_method='exact')\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_xg = optuna.create_study(direction='maximize')  \n",
    "# study_xg.optimize(objective_xg, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_xg.best_params)\n",
    "# print('Best Score:', study_xg.best_value)\n",
    "\n",
    "# best_params_xg = study_xg.best_params\n",
    "\n",
    "# with open(\"xg_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_xg.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_xg.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_lgbm(trial):\n",
    "#     # params = {\n",
    "#     #     'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "#     #     'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#     #     'num_leaves': trial.suggest_int('num_leaves', 10, 150),\n",
    "#     #     'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "#     #     'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "#     #     'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "#     #     'bagging_freq': trial.suggest_int('bagging_freq', 3, 7),\n",
    "#     #     'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),  \n",
    "#     #     'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "#     #     'n_estimators': trial.suggest_int('n_estimators', 100, 1000)  \n",
    "#     # }\n",
    "#     params = {\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-6, 0.5),      \n",
    "#         'max_depth': trial.suggest_int('max_depth', 2, 50),                   \n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 5, 300),                 \n",
    "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 200),       \n",
    "#         'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.1, 1.0),   \n",
    "#         'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),               \n",
    "#         'lambda_l1': trial.suggest_float('lambda_l1', 0, 50),                    \n",
    "#         'lambda_l2': trial.suggest_float('lambda_l2', 0, 50),\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 1500)              \n",
    "#     }\n",
    "\n",
    "\n",
    "#     model = LGBMRegressor(**params, random_state=42, verbose=-1)\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "\n",
    "#     return score\n",
    "\n",
    "# study_lgbm = optuna.create_study(direction='maximize')\n",
    "# study_lgbm.optimize(objective_lgbm, n_trials=1000)\n",
    "\n",
    "# print('Best Hyperparameters:', study_lgbm.best_params)\n",
    "# print('Best Score:', study_lgbm.best_value)\n",
    "\n",
    "# best_params_lgbm = study_lgbm.best_params\n",
    "\n",
    "# with open(\"lgbm_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_lgbm.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_lgbm.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_rf(trial):\n",
    "#     params = {\n",
    "#         'n_estimators' : trial.suggest_int(\"n_estimators\", 100, 2000),\n",
    "#         'max_depth' : trial.suggest_int(\"max_depth\", 5, 30),\n",
    "#         'min_samples_split' : trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "#         'min_samples_leaf' : trial.suggest_int(\"min_samples_leaf\", 2, 20),\n",
    "#         'max_features' : trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "#     }\n",
    "    \n",
    "#     model = RandomForestRegressor(**params, random_state=42, n_jobs=-1)\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_rf = optuna.create_study(direction='maximize')  \n",
    "# study_rf.optimize(objective_rf, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_rf.best_params)\n",
    "# print('Best Score:', study_rf.best_value)\n",
    "\n",
    "# best_params_rf = study_rf.best_params\n",
    "\n",
    "# with open(\"rf_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_rf.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_rf.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_cat(trial):\n",
    "#     params = {\n",
    "#         \"iterations\": trial.suggest_int(\"iterations\", 300, 2000),\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 0.5),\n",
    "#         \"depth\": trial.suggest_int(\"depth\", 4, 12),\n",
    "#         \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-5, 10),\n",
    "#         \"random_strength\": trial.suggest_float(\"random_strength\", 0, 10),\n",
    "#         \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0, 1),\n",
    "#         \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "#         \"loss_function\": \"RMSE\",\n",
    "#         \"eval_metric\": \"RMSE\",\n",
    "#         \"random_seed\": 42,\n",
    "#         \"verbose\": 0\n",
    "#     }\n",
    "    \n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_cat = optuna.create_study(direction='maximize')  \n",
    "# study_cat.optimize(objective_cat, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_cat.best_params)\n",
    "# print('Best Score:', study_cat.best_value)\n",
    "\n",
    "# best_params_cat = study_cat.best_params\n",
    "\n",
    "# with open(\"cat_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_cat.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_cat.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 16:49:55,762] A new study created in memory with name: no-name-723a586b-e27b-4733-90b7-7837c92268bd\n",
      "[I 2025-03-11 17:06:28,849] Trial 0 finished with value: 0.006221236770663297 and parameters: {'learning_rate': 0.7432336279370492, 'n_estimators': 1674, 'subsample': 0.5260115931690088, 'min_samples_split': 16, 'min_samples_leaf': 13, 'max_depth': 18}. Best is trial 0 with value: 0.006221236770663297.\n",
      "[I 2025-03-11 17:10:24,391] Trial 1 finished with value: 0.645954516072477 and parameters: {'learning_rate': 0.1044582819296056, 'n_estimators': 733, 'subsample': 0.6523176283463602, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_depth': 5}. Best is trial 1 with value: 0.645954516072477.\n",
      "[I 2025-03-11 17:28:02,056] Trial 2 finished with value: 0.6886036810357494 and parameters: {'learning_rate': 0.13665020064130315, 'n_estimators': 1397, 'subsample': 0.6588069771381614, 'min_samples_split': 3, 'min_samples_leaf': 14, 'max_depth': 17}. Best is trial 2 with value: 0.6886036810357494.\n",
      "[I 2025-03-11 17:41:37,113] Trial 3 finished with value: 0.06585865028022539 and parameters: {'learning_rate': 6.74455290053294e-05, 'n_estimators': 1034, 'subsample': 0.8195356186551723, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_depth': 14}. Best is trial 2 with value: 0.6886036810357494.\n",
      "[I 2025-03-11 18:05:29,575] Trial 4 finished with value: 0.5454353417127715 and parameters: {'learning_rate': 0.0008123636029318741, 'n_estimators': 1656, 'subsample': 0.9584809070783524, 'min_samples_split': 20, 'min_samples_leaf': 2, 'max_depth': 13}. Best is trial 2 with value: 0.6886036810357494.\n",
      "[I 2025-03-11 18:20:08,456] Trial 5 finished with value: 0.36484255849171043 and parameters: {'learning_rate': 0.0006273990334774352, 'n_estimators': 1094, 'subsample': 0.9607221829241924, 'min_samples_split': 5, 'min_samples_leaf': 12, 'max_depth': 13}. Best is trial 2 with value: 0.6886036810357494.\n",
      "[I 2025-03-11 18:31:46,657] Trial 6 finished with value: 0.08847151538380135 and parameters: {'learning_rate': 0.00011348398769404554, 'n_estimators': 1547, 'subsample': 0.716852833052881, 'min_samples_split': 19, 'min_samples_leaf': 17, 'max_depth': 8}. Best is trial 2 with value: 0.6886036810357494.\n",
      "[I 2025-03-11 18:32:44,433] Trial 7 finished with value: 0.005206561073623062 and parameters: {'learning_rate': 5.927374337656999e-05, 'n_estimators': 306, 'subsample': 0.7068840486150978, 'min_samples_split': 20, 'min_samples_leaf': 16, 'max_depth': 3}. Best is trial 2 with value: 0.6886036810357494.\n",
      "[I 2025-03-11 18:44:04,251] Trial 8 finished with value: 0.3421422299583839 and parameters: {'learning_rate': 0.0006461465639334529, 'n_estimators': 783, 'subsample': 0.9542421389145961, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_depth': 15}. Best is trial 2 with value: 0.6886036810357494.\n",
      "[I 2025-03-11 18:53:46,914] Trial 9 finished with value: 0.16989959769708762 and parameters: {'learning_rate': 0.0004430515205775766, 'n_estimators': 1869, 'subsample': 0.9151220043126046, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_depth': 4}. Best is trial 2 with value: 0.6886036810357494.\n",
      "[I 2025-03-11 19:10:24,877] Trial 10 finished with value: 0.7189958392583823 and parameters: {'learning_rate': 0.02892299431711534, 'n_estimators': 1303, 'subsample': 0.5668311808266779, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_depth': 20}. Best is trial 10 with value: 0.7189958392583823.\n",
      "[I 2025-03-11 19:27:31,359] Trial 11 finished with value: 0.7216794106613487 and parameters: {'learning_rate': 0.020842126244715386, 'n_estimators': 1345, 'subsample': 0.5600617596413155, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_depth': 20}. Best is trial 11 with value: 0.7216794106613487.\n",
      "[I 2025-03-11 19:40:37,739] Trial 12 finished with value: 0.7149574096391789 and parameters: {'learning_rate': 0.014432183009851492, 'n_estimators': 1165, 'subsample': 0.5103858186154453, 'min_samples_split': 11, 'min_samples_leaf': 6, 'max_depth': 20}. Best is trial 11 with value: 0.7216794106613487.\n",
      "[I 2025-03-11 19:58:12,356] Trial 13 finished with value: 0.7250688809324388 and parameters: {'learning_rate': 0.009385454017766335, 'n_estimators': 1335, 'subsample': 0.5882587490166523, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_depth': 20}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 20:14:13,552] Trial 14 finished with value: 0.6705272585498541 and parameters: {'learning_rate': 0.005774917568770978, 'n_estimators': 1940, 'subsample': 0.5992493781321251, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_depth': 10}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 20:26:25,541] Trial 15 finished with value: 0.6933928603462474 and parameters: {'learning_rate': 0.0031574074663261245, 'n_estimators': 852, 'subsample': 0.8047296076816617, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_depth': 18}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 20:28:16,918] Trial 16 finished with value: 0.6751432941236079 and parameters: {'learning_rate': 0.04781268061511459, 'n_estimators': 167, 'subsample': 0.6055636541694978, 'min_samples_split': 15, 'min_samples_leaf': 10, 'max_depth': 16}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 20:35:33,217] Trial 17 finished with value: 0.460771478601483 and parameters: {'learning_rate': 0.485052331585048, 'n_estimators': 536, 'subsample': 0.567439585892835, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_depth': 20}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 20:50:40,643] Trial 18 finished with value: 0.5653938526880266 and parameters: {'learning_rate': 0.003678142919172991, 'n_estimators': 1415, 'subsample': 0.7803331465940601, 'min_samples_split': 13, 'min_samples_leaf': 20, 'max_depth': 11}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 20:57:59,342] Trial 19 finished with value: 0.6044526961996791 and parameters: {'learning_rate': 0.011193450224120239, 'n_estimators': 988, 'subsample': 0.6624900648659524, 'min_samples_split': 17, 'min_samples_leaf': 8, 'max_depth': 8}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 21:21:18,404] Trial 20 finished with value: 0.7074286527711644 and parameters: {'learning_rate': 0.15194410501786587, 'n_estimators': 1228, 'subsample': 0.8580015594681976, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 18}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 21:38:20,383] Trial 21 finished with value: 0.7192625579199047 and parameters: {'learning_rate': 0.03328051814800267, 'n_estimators': 1357, 'subsample': 0.5674681769901159, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_depth': 20}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 21:56:06,203] Trial 22 finished with value: 0.7152160070243828 and parameters: {'learning_rate': 0.038789927588481474, 'n_estimators': 1492, 'subsample': 0.5511203356944585, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_depth': 19}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 22:11:04,958] Trial 23 finished with value: 0.6432482085166333 and parameters: {'learning_rate': 0.0017426271098919788, 'n_estimators': 1675, 'subsample': 0.5025628678733496, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_depth': 16}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 22:27:28,203] Trial 24 finished with value: 0.7105776437754285 and parameters: {'learning_rate': 0.013081703642769369, 'n_estimators': 1367, 'subsample': 0.6095838245467908, 'min_samples_split': 10, 'min_samples_leaf': 11, 'max_depth': 17}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 22:45:16,872] Trial 25 finished with value: 0.02185510317782998 and parameters: {'learning_rate': 1.3702714412456871e-05, 'n_estimators': 1825, 'subsample': 0.6334181470842103, 'min_samples_split': 14, 'min_samples_leaf': 7, 'max_depth': 19}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 23:05:46,619] Trial 26 finished with value: 0.5914404340321497 and parameters: {'learning_rate': 0.38358233872453695, 'n_estimators': 1232, 'subsample': 0.7049098449382009, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_depth': 20}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 23:22:14,665] Trial 27 finished with value: 0.7105074458710403 and parameters: {'learning_rate': 0.05202659391410168, 'n_estimators': 1560, 'subsample': 0.5503343279442849, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_depth': 16}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 23:32:20,481] Trial 28 finished with value: 0.7037441242994888 and parameters: {'learning_rate': 0.007362688881742129, 'n_estimators': 857, 'subsample': 0.5966467277755604, 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_depth': 18}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 23:44:00,303] Trial 29 finished with value: 0.7224620407958725 and parameters: {'learning_rate': 0.02188569491150973, 'n_estimators': 995, 'subsample': 0.5320857794697506, 'min_samples_split': 13, 'min_samples_leaf': 4, 'max_depth': 19}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-11 23:50:21,200] Trial 30 finished with value: -0.47904460884498484 and parameters: {'learning_rate': 0.8796278558465171, 'n_estimators': 546, 'subsample': 0.5360652080879114, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_depth': 18}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-12 00:01:45,492] Trial 31 finished with value: 0.7192460687069829 and parameters: {'learning_rate': 0.0203618054818863, 'n_estimators': 1009, 'subsample': 0.5212859899525683, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_depth': 19}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-12 00:16:35,859] Trial 32 finished with value: 0.7036854163184576 and parameters: {'learning_rate': 0.0829404717912238, 'n_estimators': 1179, 'subsample': 0.5766481217599826, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_depth': 20}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-12 00:39:18,901] Trial 33 finished with value: 0.675891786135529 and parameters: {'learning_rate': 0.1980577899359962, 'n_estimators': 1667, 'subsample': 0.641567451543681, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_depth': 17}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-12 00:53:21,338] Trial 34 finished with value: 0.6860014542665892 and parameters: {'learning_rate': 0.002714763987461998, 'n_estimators': 1332, 'subsample': 0.5364718794146125, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_depth': 19}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-12 01:03:49,160] Trial 35 finished with value: 0.7140193921904421 and parameters: {'learning_rate': 0.06827819813884875, 'n_estimators': 917, 'subsample': 0.6217092874101222, 'min_samples_split': 11, 'min_samples_leaf': 10, 'max_depth': 15}. Best is trial 13 with value: 0.7250688809324388.\n",
      "[I 2025-03-12 01:18:53,957] Trial 36 finished with value: 0.7287847282570239 and parameters: {'learning_rate': 0.022777300322912555, 'n_estimators': 1088, 'subsample': 0.678407984321987, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_depth': 17}. Best is trial 36 with value: 0.7287847282570239.\n",
      "[I 2025-03-12 01:32:34,927] Trial 37 finished with value: 0.6244680932159992 and parameters: {'learning_rate': 0.001330830142590629, 'n_estimators': 1118, 'subsample': 0.675349464906015, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_depth': 17}. Best is trial 36 with value: 0.7287847282570239.\n",
      "[I 2025-03-12 01:40:18,246] Trial 38 finished with value: 0.658062676355331 and parameters: {'learning_rate': 0.009616691127863966, 'n_estimators': 642, 'subsample': 0.7243684544830029, 'min_samples_split': 13, 'min_samples_leaf': 12, 'max_depth': 14}. Best is trial 36 with value: 0.7287847282570239.\n",
      "[I 2025-03-12 01:51:12,584] Trial 39 finished with value: 0.6200070893779059 and parameters: {'learning_rate': 0.005312528568376436, 'n_estimators': 1041, 'subsample': 0.6742330457355347, 'min_samples_split': 4, 'min_samples_leaf': 14, 'max_depth': 13}. Best is trial 36 with value: 0.7287847282570239.\n",
      "[I 2025-03-12 02:16:35,017] Trial 40 finished with value: 0.7194396580085245 and parameters: {'learning_rate': 0.1006788680376833, 'n_estimators': 1467, 'subsample': 0.7595468129339067, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 18}. Best is trial 36 with value: 0.7287847282570239.\n",
      "[I 2025-03-12 02:44:27,903] Trial 41 finished with value: 0.6799154750281713 and parameters: {'learning_rate': 0.2571322394952048, 'n_estimators': 1454, 'subsample': 0.8476089799172664, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 18}. Best is trial 36 with value: 0.7287847282570239.\n",
      "[I 2025-03-12 03:11:55,512] Trial 42 finished with value: 0.73780235373911 and parameters: {'learning_rate': 0.021683280756679753, 'n_estimators': 1567, 'subsample': 0.7756522305970804, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_depth': 19}. Best is trial 42 with value: 0.73780235373911.\n",
      "[I 2025-03-12 03:39:01,700] Trial 43 finished with value: 0.7347746808248239 and parameters: {'learning_rate': 0.020332888075396467, 'n_estimators': 1597, 'subsample': 0.758173584380165, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_depth': 19}. Best is trial 42 with value: 0.73780235373911.\n",
      "[I 2025-03-12 04:08:22,957] Trial 44 finished with value: 0.7333034480467093 and parameters: {'learning_rate': 0.022991074183586112, 'n_estimators': 1786, 'subsample': 0.7401826883052588, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_depth': 19}. Best is trial 42 with value: 0.73780235373911.\n",
      "[I 2025-03-12 04:21:27,843] Trial 45 finished with value: 0.670686344466142 and parameters: {'learning_rate': 0.016245796439188994, 'n_estimators': 1780, 'subsample': 0.7396780340714899, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_depth': 7}. Best is trial 42 with value: 0.73780235373911.\n",
      "[I 2025-03-12 04:40:08,442] Trial 46 finished with value: 0.2857423000808464 and parameters: {'learning_rate': 0.0002672837702917314, 'n_estimators': 1615, 'subsample': 0.7775652736010618, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_depth': 15}. Best is trial 42 with value: 0.73780235373911.\n",
      "[I 2025-03-12 05:04:31,632] Trial 47 finished with value: 0.7273076926244344 and parameters: {'learning_rate': 0.007709955880477232, 'n_estimators': 1727, 'subsample': 0.6949032279490013, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_depth': 17}. Best is trial 42 with value: 0.73780235373911.\n",
      "[I 2025-03-12 05:33:43,087] Trial 48 finished with value: 0.7260797260376685 and parameters: {'learning_rate': 0.0062150639834653585, 'n_estimators': 1982, 'subsample': 0.6911428474016702, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_depth': 17}. Best is trial 42 with value: 0.73780235373911.\n",
      "[I 2025-03-12 06:00:19,959] Trial 49 finished with value: 0.7347401825943225 and parameters: {'learning_rate': 0.02706816297254946, 'n_estimators': 1757, 'subsample': 0.8148385854859647, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_depth': 14}. Best is trial 42 with value: 0.73780235373911.\n"
     ]
    }
   ],
   "source": [
    "def objective_gbr(trial):\n",
    "    params = {\n",
    "        #'loss':trial.suggest_categorical('loss', ['squared_error', 'huber', 'quantile', 'absolute_error']),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        #'criterion': trial.suggest_categorical('criterion', ['friedman_mse', 'squared_error']),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "    }\n",
    "    \n",
    "    model = GradientBoostingRegressor(**params, random_state=42, criterion='squared_error')\n",
    "    # model.fit(X_train, y_train)\n",
    "\n",
    "    # preds = model.predict(X_test)\n",
    "    # score = r2_score(y_test, preds)\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "    score = scores.mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "study_gbr = optuna.create_study(direction='maximize')  \n",
    "study_gbr.optimize(objective_gbr, n_trials=100)\n",
    "\n",
    "print(\"Best Hyperparameters:\", study_gbr.best_params)\n",
    "print('Best Score:', study_gbr.best_value)\n",
    "\n",
    "best_params_gbr = study_gbr.best_params\n",
    "\n",
    "with open(\"gbr_results.txt\", \"a\") as f:\n",
    "    f.write(f\"Best Score: {study_gbr.best_value}\\n\")\n",
    "    f.write(f\"Best Hyperparameters: {study_gbr.best_params}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_hgbr(trial):\n",
    "#     params = {\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n",
    "#         'max_iter': trial.suggest_int('max_iter', 100, 2000),\n",
    "#         'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 10, 200),   \n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 100),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#         'l2_regularization': trial.suggest_loguniform('l2_regularization', 1e-5, 1.0),\n",
    "#         'max_bins': trial.suggest_int('max_bins', 100, 255),\n",
    "#     }\n",
    "    \n",
    "#     model = HistGradientBoostingRegressor(**params, random_state=42, loss='squared_error')\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_hgbr = optuna.create_study(direction='maximize')  \n",
    "# study_hgbr.optimize(objective_hgbr, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_hgbr.best_params)\n",
    "# print('Best Score:', study_hgbr.best_value)\n",
    "\n",
    "# best_params_hgbr = study_hgbr.best_params\n",
    "\n",
    "# with open(\"hgbr_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_hgbr.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_hgbr.best_params}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xg = {'n_estimators': 527, 'learning_rate': 0.0312788331848764, 'max_depth': 17, 'subsample': 0.748120538929842, 'reg_alpha': 0.001241366749156092, 'reg_lambda': 4.027151002258514}\n",
    "best_params_lgbm = {'learning_rate': 0.049306462164681195, 'max_depth': 12, 'num_leaves': 145, 'min_data_in_leaf': 8, 'feature_fraction': 0.8758609827849215, 'bagging_fraction': 0.24707848190077422, 'bagging_freq': 0, 'lambda_l1': 0.0029913663437004133, 'lambda_l2': 6.191482291982284, 'n_estimators': 1318}\n",
    "best_params_rf = {'n_estimators': 713, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
    "best_params_cat = {'iterations': 1765, 'learning_rate': 0.14385381121279203, 'depth': 9, 'l2_leaf_reg': 5.747968794164383, 'random_strength': 6.851846100297218, 'bagging_temperature': 0.010757024517070014, 'border_count': 245}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBRegressor(**best_params_xg, random_state=42, tree_method='exact')\n",
    "# model = LGBMRegressor(**best_params_lgbm, random_state=42, verbose=-1)\n",
    "# model = CatBoostRegressor(**best_params_cat, verbose=False) \n",
    "model = GradientBoostingRegressor(**best_params_gbr, random_state=42, criterion='squared_error')\n",
    "# model = HistGradientBoostingRegressor(**best_params_hgbr, random_state=42, loss='squared_error')\n",
    "# model = RandomForestRegressor(**best_params_rf, random_state=42, n_jobs=-1)\n",
    "estimators = [\n",
    "    ('xgb', XGBRegressor(**best_params_xg, random_state=42, tree_method='exact')),\n",
    "    ('cat', CatBoostRegressor(**best_params_cat, verbose=False)),\n",
    "    ('lgb', LGBMRegressor(**best_params_lgbm, random_state=42, verbose=-1)),\n",
    "#     ('gbr', GradientBoostingRegressor(**best_params_gbr, random_state=42, criterion='squared_error')),\n",
    "#     ('hgbr', HistGradientBoostingRegressor(**best_params_hgbr, random_state=42, loss='squared_error'))\n",
    "]\n",
    "model = StackingRegressor(\n",
    "    estimators=estimators, \n",
    "    final_estimator=RandomForestRegressor(**best_params_rf, random_state=42, n_jobs=-1),\n",
    "    # final_estimator=XGBRegressor(**best_params_xg, random_state=42, tree_method='exact'),\n",
    "    # final_estimator=GradientBoostingRegressor(**best_params_gbr, random_state=42, criterion='squared_error'),\n",
    "    cv=10,\n",
    "    passthrough=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(cv=10,\n",
       "                  estimators=[(&#x27;xgb&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learn...\n",
       "                                             lambda_l1=0.0029913663437004133,\n",
       "                                             lambda_l2=6.191482291982284,\n",
       "                                             learning_rate=0.049306462164681195,\n",
       "                                             max_depth=12, min_data_in_leaf=8,\n",
       "                                             n_estimators=1318, num_leaves=145,\n",
       "                                             random_state=42, verbose=-1))],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=29,\n",
       "                                                        max_features=&#x27;log2&#x27;,\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=4,\n",
       "                                                        n_estimators=713,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                  passthrough=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.StackingRegressor.html\">?<span>Documentation for StackingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingRegressor(cv=10,\n",
       "                  estimators=[(&#x27;xgb&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learn...\n",
       "                                             lambda_l1=0.0029913663437004133,\n",
       "                                             lambda_l2=6.191482291982284,\n",
       "                                             learning_rate=0.049306462164681195,\n",
       "                                             max_depth=12, min_data_in_leaf=8,\n",
       "                                             n_estimators=1318, num_leaves=145,\n",
       "                                             random_state=42, verbose=-1))],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=29,\n",
       "                                                        max_features=&#x27;log2&#x27;,\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=4,\n",
       "                                                        n_estimators=713,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                  passthrough=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.0312788331848764,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=17, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=527, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>cat</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x0000019F868E6990&gt;</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(bagging_fraction=0.24707848190077422, bagging_freq=0,\n",
       "              feature_fraction=0.8758609827849215,\n",
       "              lambda_l1=0.0029913663437004133, lambda_l2=6.191482291982284,\n",
       "              learning_rate=0.049306462164681195, max_depth=12,\n",
       "              min_data_in_leaf=8, n_estimators=1318, num_leaves=145,\n",
       "              random_state=42, verbose=-1)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=29, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                      min_samples_split=4, n_estimators=713, n_jobs=-1,\n",
       "                      random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(cv=10,\n",
       "                  estimators=[('xgb',\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learn...\n",
       "                                             lambda_l1=0.0029913663437004133,\n",
       "                                             lambda_l2=6.191482291982284,\n",
       "                                             learning_rate=0.049306462164681195,\n",
       "                                             max_depth=12, min_data_in_leaf=8,\n",
       "                                             n_estimators=1318, num_leaves=145,\n",
       "                                             random_state=42, verbose=-1))],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=29,\n",
       "                                                        max_features='log2',\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=4,\n",
       "                                                        n_estimators=713,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                  passthrough=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893462312639973"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_predictions = model.predict(X_train)\n",
    "Y_train = y_train.tolist()\n",
    "r2_score(Y_train, insample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7721847142748649"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outsample_predictions = model.predict(X_test)\n",
    "Y_test = y_test.tolist()\n",
    "r2_score(Y_test, outsample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', \n",
    "                   'B07', 'B08', 'B8A', 'B11', 'B12', 'LST', 'is_building', \n",
    "                   'Air Temp at Surface [degC]', 'Relative Humidity [percent]', \n",
    "                   'Avg Wind Speed [m/s]', 'Wind Direction [degrees]', 'Solar Flux [W/m^2]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, if submission originally has more columns, select only the ones used in training:\n",
    "submission_prepared = submission[feature_columns].copy()\n",
    "\n",
    "# Now predict:\n",
    "final_predictions = model.predict(submission_prepared)\n",
    "\n",
    "final_prediction_series = pd.Series(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('Submission_template.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'Longitude':sub['Longitude'].values, 'Latitude':sub['Latitude'].values, 'UHI Index':final_prediction_series.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
