{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Multi-dimensional arrays and datasets\n",
    "import xarray as xr\n",
    "\n",
    "# Geospatial raster data handling\n",
    "import rioxarray as rxr\n",
    "\n",
    "# Geospatial data analysis\n",
    "import geopandas as gpd\n",
    "\n",
    "# Geospatial operations\n",
    "import rasterio\n",
    "from rasterio import windows  \n",
    "from rasterio import features  \n",
    "from rasterio import warp\n",
    "from rasterio.warp import transform_bounds \n",
    "from rasterio.windows import from_bounds \n",
    "\n",
    "import pyogrio\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image\n",
    "\n",
    "# Coordinate transformations\n",
    "from pyproj import Proj, Transformer, CRS\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Feature Importance\n",
    "import shap \n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor    \n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "# from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "import optuna\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "\n",
    "# Others\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('UHI_data.csv')\n",
    "bronx_df = pd.read_excel('NY_Mesonet_Weather.xlsx', sheet_name='Bronx')\n",
    "manhattan_df = pd.read_excel('NY_Mesonet_Weather.xlsx', sheet_name='Manhattan')\n",
    "submission = pd.read_csv('Validation_with_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_train_data(df, bronx, manhattan, tolerance=0.01, bronx_lat=40.87248,\n",
    "               bronx_lon=-73.89352, manhattan_lat=40.76754, manhattan_lon=-73.96449):\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "    bronx['Date / Time'] = pd.to_datetime(bronx['Date / Time'])\n",
    "    manhattan['Date / Time'] = pd.to_datetime(manhattan['Date / Time'])\n",
    "\n",
    "    bronx.rename(columns={'Date / Time': 'datetime'}, inplace=True)\n",
    "    manhattan.rename(columns={'Date / Time': 'datetime'}, inplace=True)\n",
    "\n",
    "    # Filter CSV for Manhattan based on coordinate tolerance:\n",
    "    manhattan_csv = df[\n",
    "        (df['Latitude'].between(manhattan_lat - tolerance, manhattan_lat + tolerance)) |\n",
    "        (df['Longitude'].between(manhattan_lon - tolerance, manhattan_lon + tolerance))\n",
    "    ]\n",
    "\n",
    "    bronx_csv = df[\n",
    "        (df['Latitude'].between(bronx_lat - tolerance, bronx_lat + tolerance)) |\n",
    "        (df['Longitude'].between(bronx_lon - tolerance, bronx_lon + tolerance))\n",
    "    ]\n",
    "\n",
    "    print(\"Manhattan CSV rows found:\", len(manhattan_csv))\n",
    "    print(\"Bronx CSV rows found:\", len(bronx_csv))\n",
    "\n",
    "    # Merge the temperature data from Excel with the corresponding CSV data based on datetime.\n",
    "    # For Manhattan:\n",
    "    merged_manhattan = pd.merge(manhattan_csv, manhattan, on='datetime', how='inner')\n",
    "    print(\"Merged Manhattan data:\")\n",
    "    print(merged_manhattan.head())\n",
    "\n",
    "    # For Bronx, if any rows are found; if not, consider a wider tolerance\n",
    "    if not bronx_csv.empty:\n",
    "        merged_bronx = pd.merge(bronx_csv, bronx, on='datetime', how='inner')\n",
    "        print(\"Merged Bronx data:\")\n",
    "        print(merged_bronx.head())\n",
    "    else:\n",
    "        print(\"No Bronx rows found in CSV with tolerance of Â±0.01. Consider increasing tolerance.\")\n",
    "\n",
    "    manhattan_lookup = merged_manhattan[['Longitude', 'Latitude',\n",
    "                                      'Air Temp at Surface [degC]',\n",
    "                                      'Relative Humidity [percent]',\n",
    "                                      'Avg Wind Speed [m/s]',\n",
    "                                      'Wind Direction [degrees]',\n",
    "                                      'Solar Flux [W/m^2]']]\n",
    "\n",
    "    bronx_lookup = merged_bronx[['Longitude', 'Latitude',\n",
    "                                'Air Temp at Surface [degC]',\n",
    "                                'Relative Humidity [percent]',\n",
    "                                'Avg Wind Speed [m/s]',\n",
    "                                'Wind Direction [degrees]',\n",
    "                                'Solar Flux [W/m^2]']]\n",
    "\n",
    "    # Combine (concatenate) the two lookup DataFrames into one.\n",
    "    lookup = pd.concat([manhattan_lookup, bronx_lookup])\n",
    "\n",
    "    # Now merge the main DataFrame (uhi) with the combined lookup DataFrame on the key columns.\n",
    "    df = pd.merge(df, lookup, on=['Longitude', 'Latitude'], how='left')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan CSV rows found: 247\n",
      "Bronx CSV rows found: 161\n",
      "Merged Manhattan data:\n",
      "   Longitude   Latitude            datetime  UHI Index     B01     B02  \\\n",
      "0 -73.982343  40.768468 2021-07-24 15:55:00   0.966339  1045.0  1104.0   \n",
      "1 -73.982388  40.768360 2021-07-24 15:55:00   0.966339  1045.0  1342.0   \n",
      "2 -73.982418  40.768285 2021-07-24 15:55:00   0.970667  1045.0  1108.0   \n",
      "3 -73.982428  40.768205 2021-07-24 15:55:00   0.970667  1045.0  1260.0   \n",
      "4 -73.982407  40.767880 2021-07-24 15:55:00   0.968503  1296.0   940.0   \n",
      "\n",
      "      B03     B04     B05     B06  ...     B8A     B11     B12        LST  \\\n",
      "0  1420.0  1378.0  1682.0  2171.0  ...  2506.0  1868.0  1518.0  36.753292   \n",
      "1  1564.0  1500.0  2004.0  2903.0  ...  3020.0  1806.0  1280.0  36.753292   \n",
      "2  1252.0  1290.0  1699.0  1999.0  ...  2169.0  1614.0  1351.0  36.753292   \n",
      "3  1280.0   998.0  1699.0  1999.0  ...  2169.0  1614.0  1351.0  36.305531   \n",
      "4   993.0   929.0  1880.0  2287.0  ...  2361.0  2135.0  1826.0  35.608255   \n",
      "\n",
      "   is_building  Air Temp at Surface [degC]  Relative Humidity [percent]  \\\n",
      "0            0                        26.8                         46.7   \n",
      "1            0                        26.8                         46.7   \n",
      "2            0                        26.8                         46.7   \n",
      "3            0                        26.8                         46.7   \n",
      "4            0                        26.8                         46.7   \n",
      "\n",
      "   Avg Wind Speed [m/s]  Wind Direction [degrees]  Solar Flux [W/m^2]  \n",
      "0                   3.4                       196                 605  \n",
      "1                   3.4                       196                 605  \n",
      "2                   3.4                       196                 605  \n",
      "3                   3.4                       196                 605  \n",
      "4                   3.4                       196                 605  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Merged Bronx data:\n",
      "   Longitude   Latitude            datetime  UHI Index     B01     B02  \\\n",
      "0 -73.893698  40.844500 2021-07-24 15:55:00   0.992905  1501.0  1306.0   \n",
      "1 -73.893788  40.844537 2021-07-24 15:55:00   0.992905  1501.0  2032.0   \n",
      "2 -73.893860  40.844570 2021-07-24 15:55:00   0.990741  1501.0  1260.0   \n",
      "3 -73.893913  40.844597 2021-07-24 15:55:00   0.990741  1501.0  1260.0   \n",
      "4 -73.893957  40.844605 2021-07-24 15:55:00   0.990741  1501.0   805.0   \n",
      "\n",
      "      B03     B04     B05     B06  ...     B8A     B11     B12        LST  \\\n",
      "0  1418.0  1892.0  3095.0  2881.0  ...  3191.0  3552.0  3092.0  35.680033   \n",
      "1  1858.0  2248.0  3258.0  3872.0  ...  3802.0  3694.0  3998.0  35.680033   \n",
      "2  1210.0  1836.0  3258.0  3872.0  ...  3802.0  3694.0  3998.0  35.594583   \n",
      "3  1210.0  1836.0  3258.0  3872.0  ...  3802.0  3694.0  3998.0  34.979339   \n",
      "4   844.0   816.0  2013.0  1737.0  ...  2064.0  2499.0  1941.0  34.979339   \n",
      "\n",
      "   is_building  Air Temp at Surface [degC]  Relative Humidity [percent]  \\\n",
      "0            0                        27.2                         47.3   \n",
      "1            0                        27.2                         47.3   \n",
      "2            0                        27.2                         47.3   \n",
      "3            0                        27.2                         47.3   \n",
      "4            0                        27.2                         47.3   \n",
      "\n",
      "   Avg Wind Speed [m/s]  Wind Direction [degrees]  Solar Flux [W/m^2]  \n",
      "0                   2.6                       165                 621  \n",
      "1                   2.6                       165                 621  \n",
      "2                   2.6                       165                 621  \n",
      "3                   2.6                       165                 621  \n",
      "4                   2.6                       165                 621  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "uhi = merge_train_data(df, bronx_df, manhattan_df, tolerance=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=10, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_cols = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', \n",
    "                'B07', 'B08', 'B8A', 'B11', 'B12']\n",
    "weather_cols = [\n",
    "    'Air Temp at Surface [degC]',\n",
    "    'Relative Humidity [percent]',\n",
    "    'Avg Wind Speed [m/s]',\n",
    "    'Wind Direction [degrees]',\n",
    "    'Solar Flux [W/m^2]'\n",
    "]\n",
    "\n",
    "coord_cols=['Longitude', 'Latitude']\n",
    "\n",
    "impute_cols = coord_cols + band_cols + weather_cols\n",
    "\n",
    "# Check that all required columns exist in uhi.\n",
    "missing_cols = [col for col in impute_cols if col not in uhi.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"The following columns are missing from the DataFrame: {missing_cols}\")\n",
    "\n",
    "# Create a copy of the relevant data for imputation.\n",
    "data_to_impute = uhi[impute_cols].copy()\n",
    "\n",
    "# Initialize the KNNImputer.\n",
    "imputer = KNNImputer(n_neighbors=10, weights='distance')\n",
    "\n",
    "# Fit and transform the data.\n",
    "imputed_array = imputer.fit_transform(data_to_impute)\n",
    "\n",
    "# The imputed_array has the same order as impute_cols.\n",
    "# Extract the imputed weather data columns. They are at the end of the array.\n",
    "weather_start_idx = len(coord_cols) + len(band_cols)\n",
    "imputed_weather = imputed_array[:, weather_start_idx:]\n",
    "\n",
    "uhi[weather_cols] = imputed_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weather_cols:\n",
    "    if col not in submission.columns:\n",
    "        submission[col] = np.nan\n",
    "\n",
    "test_for_impute = submission[impute_cols].copy()\n",
    "\n",
    "# Use the trained imputer to transform the test data.\n",
    "imputed_array = imputer.transform(test_for_impute)\n",
    "\n",
    "# The imputer was trained on data with columns in the order:\n",
    "#   coord_cols + band_cols + weather_cols.\n",
    "# Extract the imputed weather columns (the last len(weather_cols) columns).\n",
    "imputed_weather = imputed_array[:, -len(weather_cols):]\n",
    "\n",
    "# Update the test DataFrame's weather columns with the imputed values.\n",
    "submission[weather_cols] = imputed_weather\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y), and then into training and testing sets\n",
    "X = uhi.drop(columns=['Longitude','Latitude','datetime','UHI Index']).values\n",
    "y = uhi['UHI Index'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_xg(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "#         # 'tree_method': trial.suggest_categorical('tree_method', ['exact', 'approx', 'hist'])\n",
    "#     }\n",
    "    \n",
    "#     model = XGBRegressor(**params, random_state=42, tree_method='exact')\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_xg = optuna.create_study(direction='maximize')  \n",
    "# study_xg.optimize(objective_xg, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_xg.best_params)\n",
    "# print('Best Score:', study_xg.best_value)\n",
    "\n",
    "# best_params_xg = study_xg.best_params\n",
    "\n",
    "# with open(\"xg_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_xg.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_xg.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_lgbm(trial):\n",
    "#     # params = {\n",
    "#     #     'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "#     #     'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#     #     'num_leaves': trial.suggest_int('num_leaves', 10, 150),\n",
    "#     #     'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "#     #     'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "#     #     'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "#     #     'bagging_freq': trial.suggest_int('bagging_freq', 3, 7),\n",
    "#     #     'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),  \n",
    "#     #     'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "#     #     'n_estimators': trial.suggest_int('n_estimators', 100, 1000)  \n",
    "#     # }\n",
    "#     params = {\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-6, 0.5),      \n",
    "#         'max_depth': trial.suggest_int('max_depth', 2, 50),                   \n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 5, 300),                 \n",
    "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 200),       \n",
    "#         'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.1, 1.0),   \n",
    "#         'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),               \n",
    "#         'lambda_l1': trial.suggest_float('lambda_l1', 0, 50),                    \n",
    "#         'lambda_l2': trial.suggest_float('lambda_l2', 0, 50),\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 1500)              \n",
    "#     }\n",
    "\n",
    "\n",
    "#     model = LGBMRegressor(**params, random_state=42, verbose=-1)\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "\n",
    "#     return score\n",
    "\n",
    "# study_lgbm = optuna.create_study(direction='maximize')\n",
    "# study_lgbm.optimize(objective_lgbm, n_trials=1000)\n",
    "\n",
    "# print('Best Hyperparameters:', study_lgbm.best_params)\n",
    "# print('Best Score:', study_lgbm.best_value)\n",
    "\n",
    "# best_params_lgbm = study_lgbm.best_params\n",
    "\n",
    "# with open(\"lgbm_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_lgbm.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_lgbm.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_rf(trial):\n",
    "#     params = {\n",
    "#         'n_estimators' : trial.suggest_int(\"n_estimators\", 100, 2000),\n",
    "#         'max_depth' : trial.suggest_int(\"max_depth\", 5, 30),\n",
    "#         'min_samples_split' : trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "#         'min_samples_leaf' : trial.suggest_int(\"min_samples_leaf\", 2, 20),\n",
    "#         'max_features' : trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "#     }\n",
    "    \n",
    "#     model = RandomForestRegressor(**params, random_state=42, n_jobs=-1)\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_rf = optuna.create_study(direction='maximize')  \n",
    "# study_rf.optimize(objective_rf, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_rf.best_params)\n",
    "# print('Best Score:', study_rf.best_value)\n",
    "\n",
    "# best_params_rf = study_rf.best_params\n",
    "\n",
    "# with open(\"rf_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_rf.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_rf.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_cat(trial):\n",
    "#     params = {\n",
    "#         \"iterations\": trial.suggest_int(\"iterations\", 300, 2000),\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 0.5),\n",
    "#         \"depth\": trial.suggest_int(\"depth\", 4, 12),\n",
    "#         \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-5, 10),\n",
    "#         \"random_strength\": trial.suggest_float(\"random_strength\", 0, 10),\n",
    "#         \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0, 1),\n",
    "#         \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "#         \"loss_function\": \"RMSE\",\n",
    "#         \"eval_metric\": \"RMSE\",\n",
    "#         \"random_seed\": 42,\n",
    "#         \"verbose\": 0\n",
    "#     }\n",
    "    \n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_cat = optuna.create_study(direction='maximize')  \n",
    "# study_cat.optimize(objective_cat, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_cat.best_params)\n",
    "# print('Best Score:', study_cat.best_value)\n",
    "\n",
    "# best_params_cat = study_cat.best_params\n",
    "\n",
    "# with open(\"cat_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_cat.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_cat.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_gbr(trial):\n",
    "#     params = {\n",
    "#         #'loss':trial.suggest_categorical('loss', ['squared_error', 'huber', 'quantile', 'absolute_error']),\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
    "#         'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "#         #'criterion': trial.suggest_categorical('criterion', ['friedman_mse', 'squared_error']),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#     }\n",
    "    \n",
    "#     model = GradientBoostingRegressor(**params, random_state=42, criterion='squared_error')\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_gbr = optuna.create_study(direction='maximize')  \n",
    "# study_gbr.optimize(objective_gbr, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_gbr.best_params)\n",
    "# print('Best Score:', study_gbr.best_value)\n",
    "\n",
    "# best_params_gbr = study_gbr.best_params\n",
    "\n",
    "# with open(\"gbr_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_gbr.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_gbr.best_params}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 19:41:24,553] A new study created in memory with name: no-name-8c6d876c-200f-448b-a914-54c82801cf98\n",
      "[I 2025-03-12 19:41:48,510] Trial 0 finished with value: 0.44045780351928976 and parameters: {'learning_rate': 0.9338250371223097, 'max_iter': 1265, 'max_leaf_nodes': 53, 'min_samples_leaf': 29, 'max_depth': 13, 'l2_regularization': 0.09762198266686571, 'max_bins': 126}. Best is trial 0 with value: 0.44045780351928976.\n",
      "[I 2025-03-12 19:42:03,564] Trial 1 finished with value: 0.48811483899845803 and parameters: {'learning_rate': 0.01772715698182552, 'max_iter': 1740, 'max_leaf_nodes': 155, 'min_samples_leaf': 49, 'max_depth': 6, 'l2_regularization': 0.00041003971635910724, 'max_bins': 139}. Best is trial 1 with value: 0.48811483899845803.\n",
      "[I 2025-03-12 19:42:42,016] Trial 2 finished with value: 0.4771852491007597 and parameters: {'learning_rate': 0.003977231275307753, 'max_iter': 1381, 'max_leaf_nodes': 168, 'min_samples_leaf': 33, 'max_depth': 10, 'l2_regularization': 0.006999061016368199, 'max_bins': 137}. Best is trial 1 with value: 0.48811483899845803.\n",
      "[I 2025-03-12 19:43:09,239] Trial 3 finished with value: 0.4490356270053595 and parameters: {'learning_rate': 0.004577576244768059, 'max_iter': 626, 'max_leaf_nodes': 143, 'min_samples_leaf': 43, 'max_depth': 13, 'l2_regularization': 3.201283374523567e-05, 'max_bins': 224}. Best is trial 1 with value: 0.48811483899845803.\n",
      "[I 2025-03-12 19:43:19,552] Trial 4 finished with value: 0.001571959602992512 and parameters: {'learning_rate': 1.2586255127685714e-05, 'max_iter': 333, 'max_leaf_nodes': 74, 'min_samples_leaf': 46, 'max_depth': 10, 'l2_regularization': 0.28857868980103923, 'max_bins': 190}. Best is trial 1 with value: 0.48811483899845803.\n",
      "[I 2025-03-12 19:44:07,058] Trial 5 finished with value: 0.3411039690465357 and parameters: {'learning_rate': 0.001140672679753941, 'max_iter': 1472, 'max_leaf_nodes': 88, 'min_samples_leaf': 67, 'max_depth': 17, 'l2_regularization': 0.001805166049684906, 'max_bins': 161}. Best is trial 1 with value: 0.48811483899845803.\n",
      "[I 2025-03-12 19:44:32,322] Trial 6 finished with value: 0.0060145530691021794 and parameters: {'learning_rate': 1.0508983021707205e-05, 'max_iter': 1371, 'max_leaf_nodes': 46, 'min_samples_leaf': 93, 'max_depth': 10, 'l2_regularization': 1.6071519109459173e-05, 'max_bins': 112}. Best is trial 1 with value: 0.48811483899845803.\n",
      "[I 2025-03-12 19:44:43,224] Trial 7 finished with value: 0.5563076148191065 and parameters: {'learning_rate': 0.07177417981741295, 'max_iter': 1581, 'max_leaf_nodes': 19, 'min_samples_leaf': 78, 'max_depth': 6, 'l2_regularization': 0.00016782984340654833, 'max_bins': 179}. Best is trial 7 with value: 0.5563076148191065.\n",
      "[I 2025-03-12 19:44:50,191] Trial 8 finished with value: 0.587000139935516 and parameters: {'learning_rate': 0.15163688084603183, 'max_iter': 534, 'max_leaf_nodes': 95, 'min_samples_leaf': 99, 'max_depth': 13, 'l2_regularization': 0.0011595821133612632, 'max_bins': 139}. Best is trial 8 with value: 0.587000139935516.\n",
      "[I 2025-03-12 19:44:53,458] Trial 9 finished with value: 0.29837461529090337 and parameters: {'learning_rate': 0.013191079265724793, 'max_iter': 491, 'max_leaf_nodes': 12, 'min_samples_leaf': 29, 'max_depth': 10, 'l2_regularization': 6.268487506695321e-05, 'max_bins': 123}. Best is trial 8 with value: 0.587000139935516.\n",
      "[I 2025-03-12 19:45:10,792] Trial 10 finished with value: 0.517096583370503 and parameters: {'learning_rate': 0.8830574165428619, 'max_iter': 848, 'max_leaf_nodes': 122, 'min_samples_leaf': 96, 'max_depth': 20, 'l2_regularization': 0.0220601306532205, 'max_bins': 250}. Best is trial 8 with value: 0.587000139935516.\n",
      "[I 2025-03-12 19:45:18,012] Trial 11 finished with value: 0.4923372020847273 and parameters: {'learning_rate': 0.09939154518369338, 'max_iter': 1926, 'max_leaf_nodes': 197, 'min_samples_leaf': 74, 'max_depth': 3, 'l2_regularization': 0.00032458430516036274, 'max_bins': 182}. Best is trial 8 with value: 0.587000139935516.\n",
      "[I 2025-03-12 19:45:19,946] Trial 12 finished with value: 0.48147006686585375 and parameters: {'learning_rate': 0.10231581084401799, 'max_iter': 183, 'max_leaf_nodes': 22, 'min_samples_leaf': 2, 'max_depth': 6, 'l2_regularization': 0.00040311121491485376, 'max_bins': 160}. Best is trial 8 with value: 0.587000139935516.\n",
      "[I 2025-03-12 19:45:34,155] Trial 13 finished with value: 0.6387470711908646 and parameters: {'learning_rate': 0.11172931562477863, 'max_iter': 953, 'max_leaf_nodes': 103, 'min_samples_leaf': 79, 'max_depth': 15, 'l2_regularization': 0.0016435261737010216, 'max_bins': 213}. Best is trial 13 with value: 0.6387470711908646.\n",
      "[I 2025-03-12 19:45:56,330] Trial 14 finished with value: 0.15735665357424714 and parameters: {'learning_rate': 0.00047906291390095414, 'max_iter': 953, 'max_leaf_nodes': 111, 'min_samples_leaf': 100, 'max_depth': 16, 'l2_regularization': 0.003125835583059794, 'max_bins': 210}. Best is trial 13 with value: 0.6387470711908646.\n",
      "[I 2025-03-12 19:46:07,748] Trial 15 finished with value: 0.638110860386611 and parameters: {'learning_rate': 0.2907888781862128, 'max_iter': 727, 'max_leaf_nodes': 87, 'min_samples_leaf': 83, 'max_depth': 16, 'l2_regularization': 0.01881318461389339, 'max_bins': 212}. Best is trial 13 with value: 0.6387470711908646.\n",
      "[I 2025-03-12 19:46:22,166] Trial 16 finished with value: 0.6303459760188014 and parameters: {'learning_rate': 0.3253609390301442, 'max_iter': 831, 'max_leaf_nodes': 127, 'min_samples_leaf': 64, 'max_depth': 17, 'l2_regularization': 0.032176903318454395, 'max_bins': 216}. Best is trial 13 with value: 0.6387470711908646.\n",
      "[I 2025-03-12 19:46:43,052] Trial 17 finished with value: 0.5824016718354834 and parameters: {'learning_rate': 0.028707126162130364, 'max_iter': 1141, 'max_leaf_nodes': 68, 'min_samples_leaf': 81, 'max_depth': 20, 'l2_regularization': 0.011274018874406546, 'max_bins': 243}. Best is trial 13 with value: 0.6387470711908646.\n",
      "[I 2025-03-12 19:47:09,168] Trial 18 finished with value: 0.07047742627752066 and parameters: {'learning_rate': 0.0002033943978176227, 'max_iter': 710, 'max_leaf_nodes': 100, 'min_samples_leaf': 59, 'max_depth': 15, 'l2_regularization': 0.4212024924968237, 'max_bins': 200}. Best is trial 13 with value: 0.6387470711908646.\n",
      "[I 2025-03-12 19:47:28,052] Trial 19 finished with value: 0.6466044517654804 and parameters: {'learning_rate': 0.24888302207584898, 'max_iter': 1193, 'max_leaf_nodes': 74, 'min_samples_leaf': 86, 'max_depth': 18, 'l2_regularization': 0.11999453755281567, 'max_bins': 232}. Best is trial 19 with value: 0.6466044517654804.\n",
      "[I 2025-03-12 19:47:44,225] Trial 20 finished with value: 0.5693184117510754 and parameters: {'learning_rate': 0.03514490433789631, 'max_iter': 1033, 'max_leaf_nodes': 49, 'min_samples_leaf': 86, 'max_depth': 18, 'l2_regularization': 0.06005145831860163, 'max_bins': 234}. Best is trial 19 with value: 0.6466044517654804.\n",
      "[I 2025-03-12 19:47:59,993] Trial 21 finished with value: 0.6273027256493936 and parameters: {'learning_rate': 0.3941693336224648, 'max_iter': 1136, 'max_leaf_nodes': 71, 'min_samples_leaf': 86, 'max_depth': 14, 'l2_regularization': 0.15382001360079975, 'max_bins': 228}. Best is trial 19 with value: 0.6466044517654804.\n",
      "[I 2025-03-12 19:48:13,637] Trial 22 finished with value: 0.6389957065102057 and parameters: {'learning_rate': 0.3069885287995663, 'max_iter': 795, 'max_leaf_nodes': 84, 'min_samples_leaf': 76, 'max_depth': 18, 'l2_regularization': 0.8789567057500733, 'max_bins': 203}. Best is trial 19 with value: 0.6466044517654804.\n",
      "[I 2025-03-12 19:48:30,176] Trial 23 finished with value: 0.6411552524342287 and parameters: {'learning_rate': 0.2918394619644732, 'max_iter': 927, 'max_leaf_nodes': 114, 'min_samples_leaf': 71, 'max_depth': 19, 'l2_regularization': 0.5336879279643405, 'max_bins': 198}. Best is trial 19 with value: 0.6466044517654804.\n",
      "[I 2025-03-12 19:48:52,663] Trial 24 finished with value: 0.6233837635355627 and parameters: {'learning_rate': 0.43609480767738135, 'max_iter': 1200, 'max_leaf_nodes': 128, 'min_samples_leaf': 71, 'max_depth': 19, 'l2_regularization': 0.9083680703393244, 'max_bins': 197}. Best is trial 19 with value: 0.6466044517654804.\n",
      "[I 2025-03-12 19:48:59,262] Trial 25 finished with value: 0.3762821490300413 and parameters: {'learning_rate': 0.010792984983305885, 'max_iter': 410, 'max_leaf_nodes': 36, 'min_samples_leaf': 58, 'max_depth': 18, 'l2_regularization': 0.9394899730608668, 'max_bins': 168}. Best is trial 19 with value: 0.6466044517654804.\n",
      "[I 2025-03-12 19:49:14,299] Trial 26 finished with value: 0.6034151835025741 and parameters: {'learning_rate': 0.05335801077811655, 'max_iter': 878, 'max_leaf_nodes': 79, 'min_samples_leaf': 91, 'max_depth': 19, 'l2_regularization': 0.3018702065251296, 'max_bins': 255}. Best is trial 19 with value: 0.6466044517654804.\n",
      "[I 2025-03-12 19:49:33,165] Trial 27 finished with value: 0.6598389802003105 and parameters: {'learning_rate': 0.2335248409394192, 'max_iter': 1051, 'max_leaf_nodes': 60, 'min_samples_leaf': 63, 'max_depth': 20, 'l2_regularization': 0.1533145617973728, 'max_bins': 239}. Best is trial 27 with value: 0.6598389802003105.\n",
      "[I 2025-03-12 19:50:15,524] Trial 28 finished with value: 0.04708313660355359 and parameters: {'learning_rate': 6.167274011268433e-05, 'max_iter': 1639, 'max_leaf_nodes': 60, 'min_samples_leaf': 60, 'max_depth': 20, 'l2_regularization': 0.07250898619436907, 'max_bins': 241}. Best is trial 27 with value: 0.6598389802003105.\n",
      "[I 2025-03-12 19:50:35,220] Trial 29 finished with value: 0.5519712103211271 and parameters: {'learning_rate': 0.7392123251913334, 'max_iter': 1249, 'max_leaf_nodes': 38, 'min_samples_leaf': 56, 'max_depth': 19, 'l2_regularization': 0.10257615475085992, 'max_bins': 228}. Best is trial 27 with value: 0.6598389802003105.\n",
      "[I 2025-03-12 19:50:51,285] Trial 30 finished with value: 0.6530276744064538 and parameters: {'learning_rate': 0.20461818192513362, 'max_iter': 1052, 'max_leaf_nodes': 57, 'min_samples_leaf': 70, 'max_depth': 16, 'l2_regularization': 0.18434334335502575, 'max_bins': 240}. Best is trial 27 with value: 0.6598389802003105.\n",
      "[I 2025-03-12 19:51:08,287] Trial 31 finished with value: 0.6610573562810924 and parameters: {'learning_rate': 0.1546041042637983, 'max_iter': 1074, 'max_leaf_nodes': 57, 'min_samples_leaf': 68, 'max_depth': 17, 'l2_regularization': 0.18199801602543467, 'max_bins': 240}. Best is trial 31 with value: 0.6610573562810924.\n",
      "[I 2025-03-12 19:51:25,157] Trial 32 finished with value: 0.6540337731280469 and parameters: {'learning_rate': 0.17569863405378863, 'max_iter': 1047, 'max_leaf_nodes': 60, 'min_samples_leaf': 65, 'max_depth': 17, 'l2_regularization': 0.1656277451689344, 'max_bins': 238}. Best is trial 31 with value: 0.6610573562810924.\n",
      "[I 2025-03-12 19:51:48,364] Trial 33 finished with value: 0.6385688163618239 and parameters: {'learning_rate': 0.03919242593205177, 'max_iter': 1347, 'max_leaf_nodes': 59, 'min_samples_leaf': 51, 'max_depth': 16, 'l2_regularization': 0.04400428343885492, 'max_bins': 248}. Best is trial 31 with value: 0.6610573562810924.\n",
      "[I 2025-03-12 19:52:06,832] Trial 34 finished with value: 0.46002956712941295 and parameters: {'learning_rate': 0.008850639618809443, 'max_iter': 1056, 'max_leaf_nodes': 56, 'min_samples_leaf': 65, 'max_depth': 12, 'l2_regularization': 0.19790326650908585, 'max_bins': 221}. Best is trial 31 with value: 0.6610573562810924.\n",
      "[I 2025-03-12 19:52:23,431] Trial 35 finished with value: 0.4629766346529511 and parameters: {'learning_rate': 0.9577693274365523, 'max_iter': 1094, 'max_leaf_nodes': 36, 'min_samples_leaf': 36, 'max_depth': 15, 'l2_regularization': 0.009379790694265462, 'max_bins': 239}. Best is trial 31 with value: 0.6610573562810924.\n",
      "[I 2025-03-12 19:52:41,417] Trial 36 finished with value: 0.6606813183970732 and parameters: {'learning_rate': 0.15771648548915335, 'max_iter': 1473, 'max_leaf_nodes': 28, 'min_samples_leaf': 51, 'max_depth': 17, 'l2_regularization': 0.21385967119226798, 'max_bins': 254}. Best is trial 31 with value: 0.6610573562810924.\n",
      "[I 2025-03-12 19:53:02,456] Trial 37 finished with value: 0.30505053190758075 and parameters: {'learning_rate': 0.0016388374616248048, 'max_iter': 1453, 'max_leaf_nodes': 29, 'min_samples_leaf': 52, 'max_depth': 17, 'l2_regularization': 0.4221543852765716, 'max_bins': 249}. Best is trial 31 with value: 0.6610573562810924.\n",
      "[I 2025-03-12 19:53:32,459] Trial 38 finished with value: 0.47551937920780746 and parameters: {'learning_rate': 0.005222525979653125, 'max_iter': 1681, 'max_leaf_nodes': 43, 'min_samples_leaf': 39, 'max_depth': 14, 'l2_regularization': 0.0055238849168181385, 'max_bins': 254}. Best is trial 31 with value: 0.6610573562810924.\n",
      "[I 2025-03-12 19:53:49,178] Trial 39 finished with value: 0.5393761578651795 and parameters: {'learning_rate': 0.023014714906739755, 'max_iter': 1960, 'max_leaf_nodes': 18, 'min_samples_leaf': 44, 'max_depth': 12, 'l2_regularization': 0.033983922303520445, 'max_bins': 220}. Best is trial 31 with value: 0.6610573562810924.\n",
      "[I 2025-03-12 19:54:10,487] Trial 40 finished with value: 0.6692735014805733 and parameters: {'learning_rate': 0.05727521080564289, 'max_iter': 1530, 'max_leaf_nodes': 65, 'min_samples_leaf': 23, 'max_depth': 8, 'l2_regularization': 0.07473546766363796, 'max_bins': 235}. Best is trial 40 with value: 0.6692735014805733.\n",
      "[I 2025-03-12 19:54:19,625] Trial 41 finished with value: 0.5728283574989147 and parameters: {'learning_rate': 0.06399131716017231, 'max_iter': 1526, 'max_leaf_nodes': 67, 'min_samples_leaf': 19, 'max_depth': 4, 'l2_regularization': 0.09078409420678527, 'max_bins': 234}. Best is trial 40 with value: 0.6692735014805733.\n",
      "[I 2025-03-12 19:54:55,325] Trial 42 finished with value: 0.6865339633466727 and parameters: {'learning_rate': 0.1279725509837642, 'max_iter': 1832, 'max_leaf_nodes': 49, 'min_samples_leaf': 3, 'max_depth': 8, 'l2_regularization': 0.2852021129584376, 'max_bins': 245}. Best is trial 42 with value: 0.6865339633466727.\n",
      "[I 2025-03-12 19:55:29,453] Trial 43 finished with value: 0.6961812923549167 and parameters: {'learning_rate': 0.06912946727273978, 'max_iter': 1815, 'max_leaf_nodes': 48, 'min_samples_leaf': 3, 'max_depth': 7, 'l2_regularization': 0.27400184891878104, 'max_bins': 246}. Best is trial 43 with value: 0.6961812923549167.\n",
      "[I 2025-03-12 19:55:52,600] Trial 44 finished with value: 0.5802331537290886 and parameters: {'learning_rate': 0.016621924204392086, 'max_iter': 1838, 'max_leaf_nodes': 26, 'min_samples_leaf': 3, 'max_depth': 8, 'l2_regularization': 0.3272523758193334, 'max_bins': 248}. Best is trial 43 with value: 0.6961812923549167.\n",
      "[I 2025-03-12 19:56:22,184] Trial 45 finished with value: 0.6939795770117153 and parameters: {'learning_rate': 0.08712704457773546, 'max_iter': 1790, 'max_leaf_nodes': 49, 'min_samples_leaf': 11, 'max_depth': 8, 'l2_regularization': 0.6207120701014164, 'max_bins': 255}. Best is trial 43 with value: 0.6961812923549167.\n",
      "[I 2025-03-12 19:56:53,504] Trial 46 finished with value: 0.6916453035486356 and parameters: {'learning_rate': 0.06878906735679771, 'max_iter': 1816, 'max_leaf_nodes': 50, 'min_samples_leaf': 10, 'max_depth': 8, 'l2_regularization': 0.4514910156754773, 'max_bins': 226}. Best is trial 43 with value: 0.6961812923549167.\n",
      "[I 2025-03-12 19:57:24,489] Trial 47 finished with value: 0.4990215822350259 and parameters: {'learning_rate': 0.006426558892550118, 'max_iter': 1761, 'max_leaf_nodes': 47, 'min_samples_leaf': 11, 'max_depth': 8, 'l2_regularization': 0.6006276586804403, 'max_bins': 101}. Best is trial 43 with value: 0.6961812923549167.\n",
      "[I 2025-03-12 19:57:38,332] Trial 48 finished with value: 0.29177931170076266 and parameters: {'learning_rate': 0.002471055363847335, 'max_iter': 1871, 'max_leaf_nodes': 13, 'min_samples_leaf': 18, 'max_depth': 8, 'l2_regularization': 0.545302663634532, 'max_bins': 226}. Best is trial 43 with value: 0.6961812923549167.\n",
      "[I 2025-03-12 19:58:08,598] Trial 49 finished with value: 0.6968293606233511 and parameters: {'learning_rate': 0.06158337878706913, 'max_iter': 1776, 'max_leaf_nodes': 157, 'min_samples_leaf': 9, 'max_depth': 7, 'l2_regularization': 0.05690672920511885, 'max_bins': 246}. Best is trial 49 with value: 0.6968293606233511.\n",
      "[I 2025-03-12 19:58:38,369] Trial 50 finished with value: 0.6990909133105474 and parameters: {'learning_rate': 0.08720132464145108, 'max_iter': 1785, 'max_leaf_nodes': 166, 'min_samples_leaf': 9, 'max_depth': 7, 'l2_regularization': 0.38517578798736535, 'max_bins': 246}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 19:59:08,763] Trial 51 finished with value: 0.6939222899651993 and parameters: {'learning_rate': 0.10716632212139561, 'max_iter': 1762, 'max_leaf_nodes': 162, 'min_samples_leaf': 8, 'max_depth': 7, 'l2_regularization': 0.3108754587238693, 'max_bins': 244}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 19:59:25,554] Trial 52 finished with value: 0.6752004788625157 and parameters: {'learning_rate': 0.08969672472323736, 'max_iter': 1758, 'max_leaf_nodes': 166, 'min_samples_leaf': 9, 'max_depth': 5, 'l2_regularization': 0.6720137612363741, 'max_bins': 255}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:00:03,067] Trial 53 finished with value: 0.6646270578260125 and parameters: {'learning_rate': 0.0208991395732761, 'max_iter': 1995, 'max_leaf_nodes': 188, 'min_samples_leaf': 9, 'max_depth': 7, 'l2_regularization': 0.3138795770828198, 'max_bins': 247}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:00:41,837] Trial 54 finished with value: 0.6745525267830529 and parameters: {'learning_rate': 0.03361028379859393, 'max_iter': 1689, 'max_leaf_nodes': 140, 'min_samples_leaf': 13, 'max_depth': 9, 'l2_regularization': 1.0502221619187708e-05, 'max_bins': 142}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:01:07,933] Trial 55 finished with value: 0.5910451477870075 and parameters: {'learning_rate': 0.5503006589646118, 'max_iter': 1901, 'max_leaf_nodes': 152, 'min_samples_leaf': 6, 'max_depth': 6, 'l2_regularization': 0.0190943652537916, 'max_bins': 230}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:01:29,664] Trial 56 finished with value: 0.682794776779424 and parameters: {'learning_rate': 0.07772263227745731, 'max_iter': 1610, 'max_leaf_nodes': 172, 'min_samples_leaf': 16, 'max_depth': 7, 'l2_regularization': 0.42426014987638117, 'max_bins': 220}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:01:43,773] Trial 57 finished with value: 0.6044917648958013 and parameters: {'learning_rate': 0.048201286827922275, 'max_iter': 1810, 'max_leaf_nodes': 177, 'min_samples_leaf': 25, 'max_depth': 5, 'l2_regularization': 0.045485654925832744, 'max_bins': 244}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:03:26,703] Trial 58 finished with value: 0.6923064859350333 and parameters: {'learning_rate': 0.014839184458265027, 'max_iter': 1709, 'max_leaf_nodes': 159, 'min_samples_leaf': 1, 'max_depth': 9, 'l2_regularization': 0.00011567761515401961, 'max_bins': 207}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:04:45,570] Trial 59 finished with value: 0.6959081393320692 and parameters: {'learning_rate': 0.018022874472275133, 'max_iter': 1703, 'max_leaf_nodes': 158, 'min_samples_leaf': 5, 'max_depth': 10, 'l2_regularization': 6.529355520663146e-05, 'max_bins': 192}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:05:34,017] Trial 60 finished with value: 0.6845025412527784 and parameters: {'learning_rate': 0.02386228983623365, 'max_iter': 1938, 'max_leaf_nodes': 151, 'min_samples_leaf': 14, 'max_depth': 10, 'l2_regularization': 0.0011959285020297524, 'max_bins': 190}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:07:15,820] Trial 61 finished with value: 0.6827816836289414 and parameters: {'learning_rate': 0.013450384937122955, 'max_iter': 1685, 'max_leaf_nodes': 165, 'min_samples_leaf': 1, 'max_depth': 9, 'l2_regularization': 8.72805566503564e-05, 'max_bins': 174}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:08:20,154] Trial 62 finished with value: 0.6283757984011823 and parameters: {'learning_rate': 0.007495192434137634, 'max_iter': 1550, 'max_leaf_nodes': 140, 'min_samples_leaf': 6, 'max_depth': 9, 'l2_regularization': 2.8479177805386503e-05, 'max_bins': 207}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:08:50,388] Trial 63 finished with value: 0.6852046783663873 and parameters: {'learning_rate': 0.10951542458180862, 'max_iter': 1722, 'max_leaf_nodes': 159, 'min_samples_leaf': 23, 'max_depth': 11, 'l2_regularization': 0.00017443180837670445, 'max_bins': 192}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:09:25,546] Trial 64 finished with value: 0.6781293727890303 and parameters: {'learning_rate': 0.039384891258415336, 'max_iter': 1625, 'max_leaf_nodes': 176, 'min_samples_leaf': 5, 'max_depth': 7, 'l2_regularization': 5.763230501862141e-05, 'max_bins': 150}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:09:45,482] Trial 65 finished with value: 0.36058031849188443 and parameters: {'learning_rate': 0.003505489862351726, 'max_iter': 1769, 'max_leaf_nodes': 188, 'min_samples_leaf': 6, 'max_depth': 5, 'l2_regularization': 0.0005605619684876799, 'max_bins': 214}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:10:24,905] Trial 66 finished with value: 0.6198780687715135 and parameters: {'learning_rate': 0.012885296356027759, 'max_iter': 1895, 'max_leaf_nodes': 147, 'min_samples_leaf': 30, 'max_depth': 11, 'l2_regularization': 0.0001775903511277009, 'max_bins': 189}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:10:52,104] Trial 67 finished with value: 0.6483654450648942 and parameters: {'learning_rate': 0.030098402614151493, 'max_iter': 1382, 'max_leaf_nodes': 162, 'min_samples_leaf': 1, 'max_depth': 6, 'l2_regularization': 3.0075295419676636e-05, 'max_bins': 184}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:11:41,342] Trial 68 finished with value: 0.6678214536638359 and parameters: {'learning_rate': 0.016856847150048947, 'max_iter': 1658, 'max_leaf_nodes': 157, 'min_samples_leaf': 12, 'max_depth': 10, 'l2_regularization': 9.781689313629456e-05, 'max_bins': 165}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:12:03,160] Trial 69 finished with value: 0.6799927487592002 and parameters: {'learning_rate': 0.06823543498777564, 'max_iter': 1742, 'max_leaf_nodes': 134, 'min_samples_leaf': 19, 'max_depth': 7, 'l2_regularization': 0.0006224443026701784, 'max_bins': 250}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:12:34,346] Trial 70 finished with value: 0.6889894405084699 and parameters: {'learning_rate': 0.044513294440033734, 'max_iter': 1562, 'max_leaf_nodes': 184, 'min_samples_leaf': 15, 'max_depth': 9, 'l2_regularization': 4.945828857862423e-05, 'max_bins': 204}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:13:03,964] Trial 71 finished with value: 0.6955132865680256 and parameters: {'learning_rate': 0.091295250168814, 'max_iter': 1793, 'max_leaf_nodes': 200, 'min_samples_leaf': 9, 'max_depth': 7, 'l2_regularization': 0.7283069346903291, 'max_bins': 224}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:13:37,267] Trial 72 finished with value: 0.6943965290898074 and parameters: {'learning_rate': 0.09234984812594699, 'max_iter': 1804, 'max_leaf_nodes': 195, 'min_samples_leaf': 7, 'max_depth': 7, 'l2_regularization': 0.7721930959478237, 'max_bins': 243}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:14:09,620] Trial 73 finished with value: 0.6961034908419991 and parameters: {'learning_rate': 0.11046122752801792, 'max_iter': 1865, 'max_leaf_nodes': 194, 'min_samples_leaf': 8, 'max_depth': 7, 'l2_regularization': 0.752246347695692, 'max_bins': 233}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:14:21,374] Trial 74 finished with value: 0.6529792242571191 and parameters: {'learning_rate': 0.18076610949838812, 'max_iter': 1972, 'max_leaf_nodes': 198, 'min_samples_leaf': 16, 'max_depth': 4, 'l2_regularization': 0.9603907573679163, 'max_bins': 235}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:14:48,407] Trial 75 finished with value: 0.6397550047378697 and parameters: {'learning_rate': 0.4004715067910873, 'max_iter': 1867, 'max_leaf_nodes': 195, 'min_samples_leaf': 5, 'max_depth': 6, 'l2_regularization': 0.7477142998712257, 'max_bins': 251}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:15:14,966] Trial 76 finished with value: 0.676863230019984 and parameters: {'learning_rate': 0.23540156906494653, 'max_iter': 1916, 'max_leaf_nodes': 193, 'min_samples_leaf': 12, 'max_depth': 7, 'l2_regularization': 0.24052007034460884, 'max_bins': 231}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:15:32,144] Trial 77 finished with value: 0.6706921241640218 and parameters: {'learning_rate': 0.13474527741137388, 'max_iter': 1802, 'max_leaf_nodes': 183, 'min_samples_leaf': 22, 'max_depth': 6, 'l2_regularization': 0.12532601360053391, 'max_bins': 223}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:15:53,146] Trial 78 finished with value: 0.012436488078580398 and parameters: {'learning_rate': 1.981163892118815e-05, 'max_iter': 1609, 'max_leaf_nodes': 173, 'min_samples_leaf': 8, 'max_depth': 5, 'l2_regularization': 0.6680167667719562, 'max_bins': 237}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:16:32,832] Trial 79 finished with value: 0.6768788809274214 and parameters: {'learning_rate': 0.0805790494503275, 'max_iter': 1799, 'max_leaf_nodes': 200, 'min_samples_leaf': 4, 'max_depth': 7, 'l2_regularization': 0.4778678180288486, 'max_bins': 124}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:16:43,650] Trial 80 finished with value: 0.5618379629519554 and parameters: {'learning_rate': 0.0545747243357074, 'max_iter': 1874, 'max_leaf_nodes': 95, 'min_samples_leaf': 27, 'max_depth': 4, 'l2_regularization': 0.0036015392830398983, 'max_bins': 251}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:17:14,369] Trial 81 finished with value: 0.6916183534489002 and parameters: {'learning_rate': 0.10292451663594958, 'max_iter': 1736, 'max_leaf_nodes': 181, 'min_samples_leaf': 8, 'max_depth': 7, 'l2_regularization': 0.9924493731349779, 'max_bins': 243}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:17:55,089] Trial 82 finished with value: 0.6946254120629793 and parameters: {'learning_rate': 0.12508197656190329, 'max_iter': 1937, 'max_leaf_nodes': 189, 'min_samples_leaf': 8, 'max_depth': 8, 'l2_regularization': 0.3369413312520168, 'max_bins': 243}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:18:29,459] Trial 83 finished with value: 0.6878400983336584 and parameters: {'learning_rate': 0.14404213257459678, 'max_iter': 1943, 'max_leaf_nodes': 190, 'min_samples_leaf': 11, 'max_depth': 8, 'l2_regularization': 0.34862276680514387, 'max_bins': 242}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:18:35,439] Trial 84 finished with value: 0.6053204824724745 and parameters: {'learning_rate': 0.5495565882054004, 'max_iter': 240, 'max_leaf_nodes': 170, 'min_samples_leaf': 16, 'max_depth': 10, 'l2_regularization': 0.24471214106051276, 'max_bins': 231}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:18:52,927] Trial 85 finished with value: 0.6697927602992393 and parameters: {'learning_rate': 0.22360761409793437, 'max_iter': 1833, 'max_leaf_nodes': 193, 'min_samples_leaf': 21, 'max_depth': 6, 'l2_regularization': 0.7485189700907545, 'max_bins': 246}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:20:42,470] Trial 86 finished with value: 0.3134195986098192 and parameters: {'learning_rate': 0.0005145054564981744, 'max_iter': 1988, 'max_leaf_nodes': 179, 'min_samples_leaf': 7, 'max_depth': 8, 'l2_regularization': 0.5486669114182883, 'max_bins': 235}. Best is trial 50 with value: 0.6990909133105474.\n",
      "[I 2025-03-12 20:22:02,127] Trial 87 finished with value: 0.6992389649937263 and parameters: {'learning_rate': 0.090623242184738, 'max_iter': 1882, 'max_leaf_nodes': 185, 'min_samples_leaf': 3, 'max_depth': 9, 'l2_regularization': 0.12324028345241968, 'max_bins': 218}. Best is trial 87 with value: 0.6992389649937263.\n",
      "[I 2025-03-12 20:23:19,136] Trial 88 finished with value: 0.6552494670520187 and parameters: {'learning_rate': 0.33959566969428856, 'max_iter': 1862, 'max_leaf_nodes': 186, 'min_samples_leaf': 3, 'max_depth': 9, 'l2_regularization': 0.14112936915209026, 'max_bins': 217}. Best is trial 87 with value: 0.6992389649937263.\n",
      "[I 2025-03-12 20:23:42,501] Trial 89 finished with value: 0.6351917406834678 and parameters: {'learning_rate': 0.027905594396317575, 'max_iter': 1912, 'max_leaf_nodes': 192, 'min_samples_leaf': 14, 'max_depth': 6, 'l2_regularization': 0.10681242105795151, 'max_bins': 228}. Best is trial 87 with value: 0.6992389649937263.\n",
      "[I 2025-03-12 20:25:13,509] Trial 90 finished with value: 0.7070392878009251 and parameters: {'learning_rate': 0.05274640324241945, 'max_iter': 1939, 'max_leaf_nodes': 198, 'min_samples_leaf': 4, 'max_depth': 10, 'l2_regularization': 0.012815378729442072, 'max_bins': 224}. Best is trial 90 with value: 0.7070392878009251.\n",
      "[I 2025-03-12 20:26:44,566] Trial 91 finished with value: 0.7027121724905923 and parameters: {'learning_rate': 0.05652489432442934, 'max_iter': 1945, 'max_leaf_nodes': 185, 'min_samples_leaf': 4, 'max_depth': 10, 'l2_regularization': 0.3918760848237458, 'max_bins': 218}. Best is trial 90 with value: 0.7070392878009251.\n",
      "[I 2025-03-12 20:28:31,780] Trial 92 finished with value: 0.7034587087499584 and parameters: {'learning_rate': 0.05078196100677871, 'max_iter': 1995, 'max_leaf_nodes': 199, 'min_samples_leaf': 4, 'max_depth': 11, 'l2_regularization': 0.01440893192921075, 'max_bins': 217}. Best is trial 90 with value: 0.7070392878009251.\n",
      "[I 2025-03-12 20:30:30,735] Trial 93 finished with value: 0.70524802601463 and parameters: {'learning_rate': 0.04540466541897347, 'max_iter': 1968, 'max_leaf_nodes': 200, 'min_samples_leaf': 3, 'max_depth': 11, 'l2_regularization': 0.013078710437835041, 'max_bins': 217}. Best is trial 90 with value: 0.7070392878009251.\n",
      "[I 2025-03-12 20:32:23,159] Trial 94 finished with value: 0.7103293500022467 and parameters: {'learning_rate': 0.04441308386515432, 'max_iter': 1984, 'max_leaf_nodes': 175, 'min_samples_leaf': 3, 'max_depth': 11, 'l2_regularization': 0.012220433265594653, 'max_bins': 210}. Best is trial 94 with value: 0.7103293500022467.\n",
      "[I 2025-03-12 20:34:17,621] Trial 95 finished with value: 0.7057529422779591 and parameters: {'learning_rate': 0.04911994830393344, 'max_iter': 1990, 'max_leaf_nodes': 182, 'min_samples_leaf': 3, 'max_depth': 11, 'l2_regularization': 0.01262136797956441, 'max_bins': 211}. Best is trial 94 with value: 0.7103293500022467.\n",
      "[I 2025-03-12 20:36:15,797] Trial 96 finished with value: 0.7060088604592167 and parameters: {'learning_rate': 0.04331339934989622, 'max_iter': 1987, 'max_leaf_nodes': 175, 'min_samples_leaf': 3, 'max_depth': 12, 'l2_regularization': 0.01480245448262563, 'max_bins': 216}. Best is trial 94 with value: 0.7103293500022467.\n",
      "[I 2025-03-12 20:38:16,474] Trial 97 finished with value: 0.7057556696628557 and parameters: {'learning_rate': 0.03950121971003911, 'max_iter': 1992, 'max_leaf_nodes': 180, 'min_samples_leaf': 3, 'max_depth': 12, 'l2_regularization': 0.013514431411691083, 'max_bins': 211}. Best is trial 94 with value: 0.7103293500022467.\n",
      "[I 2025-03-12 20:40:42,739] Trial 98 finished with value: 0.7080285317166767 and parameters: {'learning_rate': 0.0404238108088245, 'max_iter': 1998, 'max_leaf_nodes': 175, 'min_samples_leaf': 1, 'max_depth': 13, 'l2_regularization': 0.011544548283458939, 'max_bins': 211}. Best is trial 94 with value: 0.7103293500022467.\n",
      "[I 2025-03-12 20:43:08,513] Trial 99 finished with value: 0.7099133300050864 and parameters: {'learning_rate': 0.038694454671929064, 'max_iter': 1989, 'max_leaf_nodes': 176, 'min_samples_leaf': 1, 'max_depth': 13, 'l2_regularization': 0.012671394765464809, 'max_bins': 209}. Best is trial 94 with value: 0.7103293500022467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.04441308386515432, 'max_iter': 1984, 'max_leaf_nodes': 175, 'min_samples_leaf': 3, 'max_depth': 11, 'l2_regularization': 0.012220433265594653, 'max_bins': 210}\n",
      "Best Score: 0.7103293500022467\n"
     ]
    }
   ],
   "source": [
    "def objective_hgbr(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 2000),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 10, 200),   \n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'l2_regularization': trial.suggest_loguniform('l2_regularization', 1e-5, 1.0),\n",
    "        'max_bins': trial.suggest_int('max_bins', 100, 255),\n",
    "    }\n",
    "    \n",
    "    model = HistGradientBoostingRegressor(**params, random_state=42, loss='squared_error')\n",
    "    # model.fit(X_train, y_train)\n",
    "\n",
    "    # preds = model.predict(X_test)\n",
    "    # score = r2_score(y_test, preds)\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "    score = scores.mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "study_hgbr = optuna.create_study(direction='maximize')  \n",
    "study_hgbr.optimize(objective_hgbr, n_trials=100)\n",
    "\n",
    "print(\"Best Hyperparameters:\", study_hgbr.best_params)\n",
    "print('Best Score:', study_hgbr.best_value)\n",
    "\n",
    "best_params_hgbr = study_hgbr.best_params\n",
    "\n",
    "with open(\"hgbr_results.txt\", \"a\") as f:\n",
    "    f.write(f\"Best Score: {study_hgbr.best_value}\\n\")\n",
    "    f.write(f\"Best Hyperparameters: {study_hgbr.best_params}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xg = {'n_estimators': 527, 'learning_rate': 0.0312788331848764, 'max_depth': 17, 'subsample': 0.748120538929842, 'reg_alpha': 0.001241366749156092, 'reg_lambda': 4.027151002258514}\n",
    "best_params_lgbm = {'learning_rate': 0.049306462164681195, 'max_depth': 12, 'num_leaves': 145, 'min_data_in_leaf': 8, 'feature_fraction': 0.8758609827849215, 'bagging_fraction': 0.24707848190077422, 'bagging_freq': 0, 'lambda_l1': 0.0029913663437004133, 'lambda_l2': 6.191482291982284, 'n_estimators': 1318}\n",
    "best_params_rf = {'n_estimators': 713, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
    "best_params_cat = {'iterations': 1765, 'learning_rate': 0.14385381121279203, 'depth': 9, 'l2_leaf_reg': 5.747968794164383, 'random_strength': 6.851846100297218, 'bagging_temperature': 0.010757024517070014, 'border_count': 245}\n",
    "best_params_gbr = {'learning_rate': 0.02706816297254946, 'n_estimators': 1757, 'subsample': 0.8148385854859647, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_depth': 14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBRegressor(**best_params_xg, random_state=42, tree_method='exact')\n",
    "# model = LGBMRegressor(**best_params_lgbm, random_state=42, verbose=-1)\n",
    "# model = CatBoostRegressor(**best_params_cat, verbose=False) \n",
    "# model = GradientBoostingRegressor(**best_params_gbr, random_state=42, criterion='squared_error')\n",
    "# model = HistGradientBoostingRegressor(**best_params_hgbr, random_state=42, loss='squared_error')\n",
    "# model = RandomForestRegressor(**best_params_rf, random_state=42, n_jobs=-1)\n",
    "estimators = [\n",
    "    ('xgb', XGBRegressor(**best_params_xg, random_state=42, tree_method='exact')),\n",
    "    ('cat', CatBoostRegressor(**best_params_cat, verbose=False)),\n",
    "    ('lgb', LGBMRegressor(**best_params_lgbm, random_state=42, verbose=-1)),\n",
    "    ('gbr', GradientBoostingRegressor(**best_params_gbr, random_state=42, criterion='squared_error')),\n",
    "    ('hgbr', HistGradientBoostingRegressor(**best_params_hgbr, random_state=42, loss='squared_error'))\n",
    "]\n",
    "model = StackingRegressor(\n",
    "    estimators=estimators, \n",
    "    final_estimator=RandomForestRegressor(**best_params_rf, random_state=42, n_jobs=-1),\n",
    "    # final_estimator=XGBRegressor(**best_params_xg, random_state=42, tree_method='exact'),\n",
    "    # final_estimator=GradientBoostingRegressor(**best_params_gbr, random_state=42, criterion='squared_error'),\n",
    "    cv=10,\n",
    "    passthrough=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(cv=10,\n",
       "                  estimators=[(&#x27;xgb&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learn...\n",
       "                               HistGradientBoostingRegressor(l2_regularization=0.012220433265594653,\n",
       "                                                             learning_rate=0.04441308386515432,\n",
       "                                                             max_bins=210,\n",
       "                                                             max_depth=11,\n",
       "                                                             max_iter=1984,\n",
       "                                                             max_leaf_nodes=175,\n",
       "                                                             min_samples_leaf=3,\n",
       "                                                             random_state=42))],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=29,\n",
       "                                                        max_features=&#x27;log2&#x27;,\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=4,\n",
       "                                                        n_estimators=713,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                  passthrough=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.StackingRegressor.html\">?<span>Documentation for StackingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingRegressor(cv=10,\n",
       "                  estimators=[(&#x27;xgb&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learn...\n",
       "                               HistGradientBoostingRegressor(l2_regularization=0.012220433265594653,\n",
       "                                                             learning_rate=0.04441308386515432,\n",
       "                                                             max_bins=210,\n",
       "                                                             max_depth=11,\n",
       "                                                             max_iter=1984,\n",
       "                                                             max_leaf_nodes=175,\n",
       "                                                             min_samples_leaf=3,\n",
       "                                                             random_state=42))],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=29,\n",
       "                                                        max_features=&#x27;log2&#x27;,\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=4,\n",
       "                                                        n_estimators=713,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                  passthrough=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.0312788331848764,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=17, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=527, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>cat</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x0000026A814610A0&gt;</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(bagging_fraction=0.24707848190077422, bagging_freq=0,\n",
       "              feature_fraction=0.8758609827849215,\n",
       "              lambda_l1=0.0029913663437004133, lambda_l2=6.191482291982284,\n",
       "              learning_rate=0.049306462164681195, max_depth=12,\n",
       "              min_data_in_leaf=8, n_estimators=1318, num_leaves=145,\n",
       "              random_state=42, verbose=-1)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gbr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;,\n",
       "                          learning_rate=0.02706816297254946, max_depth=14,\n",
       "                          min_samples_leaf=8, min_samples_split=16,\n",
       "                          n_estimators=1757, random_state=42,\n",
       "                          subsample=0.8148385854859647)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>hgbr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;HistGradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html\">?<span>Documentation for HistGradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>HistGradientBoostingRegressor(l2_regularization=0.012220433265594653,\n",
       "                              learning_rate=0.04441308386515432, max_bins=210,\n",
       "                              max_depth=11, max_iter=1984, max_leaf_nodes=175,\n",
       "                              min_samples_leaf=3, random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=29, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                      min_samples_split=4, n_estimators=713, n_jobs=-1,\n",
       "                      random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(cv=10,\n",
       "                  estimators=[('xgb',\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learn...\n",
       "                               HistGradientBoostingRegressor(l2_regularization=0.012220433265594653,\n",
       "                                                             learning_rate=0.04441308386515432,\n",
       "                                                             max_bins=210,\n",
       "                                                             max_depth=11,\n",
       "                                                             max_iter=1984,\n",
       "                                                             max_leaf_nodes=175,\n",
       "                                                             min_samples_leaf=3,\n",
       "                                                             random_state=42))],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=29,\n",
       "                                                        max_features='log2',\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=4,\n",
       "                                                        n_estimators=713,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                  passthrough=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917364448188186"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_predictions = model.predict(X_train)\n",
    "Y_train = y_train.tolist()\n",
    "r2_score(Y_train, insample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7788020675303828"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outsample_predictions = model.predict(X_test)\n",
    "Y_test = y_test.tolist()\n",
    "r2_score(Y_test, outsample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', \n",
    "                   'B07', 'B08', 'B8A', 'B11', 'B12', 'LST', 'is_building', \n",
    "                   'Air Temp at Surface [degC]', 'Relative Humidity [percent]', \n",
    "                   'Avg Wind Speed [m/s]', 'Wind Direction [degrees]', 'Solar Flux [W/m^2]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, if submission originally has more columns, select only the ones used in training:\n",
    "submission_prepared = submission[feature_columns].copy()\n",
    "\n",
    "# Now predict:\n",
    "final_predictions = model.predict(submission_prepared)\n",
    "\n",
    "final_prediction_series = pd.Series(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('Submission_template.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'Longitude':sub['Longitude'].values, 'Latitude':sub['Latitude'].values, 'UHI Index':final_prediction_series.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
