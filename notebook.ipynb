{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Multi-dimensional arrays and datasets\n",
    "import xarray as xr\n",
    "\n",
    "# Geospatial raster data handling\n",
    "import rioxarray as rxr\n",
    "\n",
    "# Geospatial data analysis\n",
    "import geopandas as gpd\n",
    "\n",
    "# Geospatial operations\n",
    "import rasterio\n",
    "from rasterio import windows  \n",
    "from rasterio import features  \n",
    "from rasterio import warp\n",
    "from rasterio.warp import transform_bounds \n",
    "from rasterio.windows import from_bounds \n",
    "\n",
    "import pyogrio\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image\n",
    "\n",
    "# Coordinate transformations\n",
    "from pyproj import Proj, Transformer, CRS\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Feature Importance\n",
    "import shap \n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor    \n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "# from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "import optuna\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "\n",
    "# Others\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('UHI_data.csv')\n",
    "bronx_df = pd.read_excel('NY_Mesonet_Weather.xlsx', sheet_name='Bronx')\n",
    "manhattan_df = pd.read_excel('NY_Mesonet_Weather.xlsx', sheet_name='Manhattan')\n",
    "submission = pd.read_csv('Validation_with_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_train_data(df, bronx, manhattan, tolerance=0.01, bronx_lat=40.87248,\n",
    "               bronx_lon=-73.89352, manhattan_lat=40.76754, manhattan_lon=-73.96449):\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "    bronx['Date / Time'] = pd.to_datetime(bronx['Date / Time'])\n",
    "    manhattan['Date / Time'] = pd.to_datetime(manhattan['Date / Time'])\n",
    "\n",
    "    bronx.rename(columns={'Date / Time': 'datetime'}, inplace=True)\n",
    "    manhattan.rename(columns={'Date / Time': 'datetime'}, inplace=True)\n",
    "\n",
    "    # Filter CSV for Manhattan based on coordinate tolerance:\n",
    "    manhattan_csv = df[\n",
    "        (df['Latitude'].between(manhattan_lat - tolerance, manhattan_lat + tolerance)) |\n",
    "        (df['Longitude'].between(manhattan_lon - tolerance, manhattan_lon + tolerance))\n",
    "    ]\n",
    "\n",
    "    bronx_csv = df[\n",
    "        (df['Latitude'].between(bronx_lat - tolerance, bronx_lat + tolerance)) |\n",
    "        (df['Longitude'].between(bronx_lon - tolerance, bronx_lon + tolerance))\n",
    "    ]\n",
    "\n",
    "    print(\"Manhattan CSV rows found:\", len(manhattan_csv))\n",
    "    print(\"Bronx CSV rows found:\", len(bronx_csv))\n",
    "\n",
    "    # Merge the temperature data from Excel with the corresponding CSV data based on datetime.\n",
    "    # For Manhattan:\n",
    "    merged_manhattan = pd.merge(manhattan_csv, manhattan, on='datetime', how='inner')\n",
    "    print(\"Merged Manhattan data:\")\n",
    "    print(merged_manhattan.head())\n",
    "\n",
    "    # For Bronx, if any rows are found; if not, consider a wider tolerance\n",
    "    if not bronx_csv.empty:\n",
    "        merged_bronx = pd.merge(bronx_csv, bronx, on='datetime', how='inner')\n",
    "        print(\"Merged Bronx data:\")\n",
    "        print(merged_bronx.head())\n",
    "    else:\n",
    "        print(\"No Bronx rows found in CSV with tolerance of ±0.01. Consider increasing tolerance.\")\n",
    "\n",
    "    manhattan_lookup = merged_manhattan[['Longitude', 'Latitude',\n",
    "                                      'Air Temp at Surface [degC]',\n",
    "                                      'Relative Humidity [percent]',\n",
    "                                      'Avg Wind Speed [m/s]',\n",
    "                                      'Wind Direction [degrees]',\n",
    "                                      'Solar Flux [W/m^2]']]\n",
    "\n",
    "    bronx_lookup = merged_bronx[['Longitude', 'Latitude',\n",
    "                                'Air Temp at Surface [degC]',\n",
    "                                'Relative Humidity [percent]',\n",
    "                                'Avg Wind Speed [m/s]',\n",
    "                                'Wind Direction [degrees]',\n",
    "                                'Solar Flux [W/m^2]']]\n",
    "\n",
    "    # Combine (concatenate) the two lookup DataFrames into one.\n",
    "    lookup = pd.concat([manhattan_lookup, bronx_lookup])\n",
    "\n",
    "    # Now merge the main DataFrame (uhi) with the combined lookup DataFrame on the key columns.\n",
    "    df = pd.merge(df, lookup, on=['Longitude', 'Latitude'], how='left')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan CSV rows found: 247\n",
      "Bronx CSV rows found: 161\n",
      "Merged Manhattan data:\n",
      "   Longitude   Latitude            datetime  UHI Index     B01     B02  \\\n",
      "0 -73.982343  40.768468 2021-07-24 15:55:00   0.966339  1045.0  1104.0   \n",
      "1 -73.982388  40.768360 2021-07-24 15:55:00   0.966339  1045.0  1342.0   \n",
      "2 -73.982418  40.768285 2021-07-24 15:55:00   0.970667  1045.0  1108.0   \n",
      "3 -73.982428  40.768205 2021-07-24 15:55:00   0.970667  1045.0  1260.0   \n",
      "4 -73.982407  40.767880 2021-07-24 15:55:00   0.968503  1296.0   940.0   \n",
      "\n",
      "      B03     B04     B05     B06  ...     B8A     B11     B12        LST  \\\n",
      "0  1420.0  1378.0  1682.0  2171.0  ...  2506.0  1868.0  1518.0  36.753292   \n",
      "1  1564.0  1500.0  2004.0  2903.0  ...  3020.0  1806.0  1280.0  36.753292   \n",
      "2  1252.0  1290.0  1699.0  1999.0  ...  2169.0  1614.0  1351.0  36.753292   \n",
      "3  1280.0   998.0  1699.0  1999.0  ...  2169.0  1614.0  1351.0  36.305531   \n",
      "4   993.0   929.0  1880.0  2287.0  ...  2361.0  2135.0  1826.0  35.608255   \n",
      "\n",
      "   is_building  Air Temp at Surface [degC]  Relative Humidity [percent]  \\\n",
      "0            0                        26.8                         46.7   \n",
      "1            0                        26.8                         46.7   \n",
      "2            0                        26.8                         46.7   \n",
      "3            0                        26.8                         46.7   \n",
      "4            0                        26.8                         46.7   \n",
      "\n",
      "   Avg Wind Speed [m/s]  Wind Direction [degrees]  Solar Flux [W/m^2]  \n",
      "0                   3.4                       196                 605  \n",
      "1                   3.4                       196                 605  \n",
      "2                   3.4                       196                 605  \n",
      "3                   3.4                       196                 605  \n",
      "4                   3.4                       196                 605  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Merged Bronx data:\n",
      "   Longitude   Latitude            datetime  UHI Index     B01     B02  \\\n",
      "0 -73.893698  40.844500 2021-07-24 15:55:00   0.992905  1501.0  1306.0   \n",
      "1 -73.893788  40.844537 2021-07-24 15:55:00   0.992905  1501.0  2032.0   \n",
      "2 -73.893860  40.844570 2021-07-24 15:55:00   0.990741  1501.0  1260.0   \n",
      "3 -73.893913  40.844597 2021-07-24 15:55:00   0.990741  1501.0  1260.0   \n",
      "4 -73.893957  40.844605 2021-07-24 15:55:00   0.990741  1501.0   805.0   \n",
      "\n",
      "      B03     B04     B05     B06  ...     B8A     B11     B12        LST  \\\n",
      "0  1418.0  1892.0  3095.0  2881.0  ...  3191.0  3552.0  3092.0  35.680033   \n",
      "1  1858.0  2248.0  3258.0  3872.0  ...  3802.0  3694.0  3998.0  35.680033   \n",
      "2  1210.0  1836.0  3258.0  3872.0  ...  3802.0  3694.0  3998.0  35.594583   \n",
      "3  1210.0  1836.0  3258.0  3872.0  ...  3802.0  3694.0  3998.0  34.979339   \n",
      "4   844.0   816.0  2013.0  1737.0  ...  2064.0  2499.0  1941.0  34.979339   \n",
      "\n",
      "   is_building  Air Temp at Surface [degC]  Relative Humidity [percent]  \\\n",
      "0            0                        27.2                         47.3   \n",
      "1            0                        27.2                         47.3   \n",
      "2            0                        27.2                         47.3   \n",
      "3            0                        27.2                         47.3   \n",
      "4            0                        27.2                         47.3   \n",
      "\n",
      "   Avg Wind Speed [m/s]  Wind Direction [degrees]  Solar Flux [W/m^2]  \n",
      "0                   2.6                       165                 621  \n",
      "1                   2.6                       165                 621  \n",
      "2                   2.6                       165                 621  \n",
      "3                   2.6                       165                 621  \n",
      "4                   2.6                       165                 621  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "uhi = merge_train_data(df, bronx_df, manhattan_df, tolerance=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=10, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_cols = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', \n",
    "                'B07', 'B08', 'B8A', 'B11', 'B12']\n",
    "weather_cols = [\n",
    "    'Air Temp at Surface [degC]',\n",
    "    'Relative Humidity [percent]',\n",
    "    'Avg Wind Speed [m/s]',\n",
    "    'Wind Direction [degrees]',\n",
    "    'Solar Flux [W/m^2]'\n",
    "]\n",
    "\n",
    "coord_cols=['Longitude', 'Latitude']\n",
    "\n",
    "impute_cols = coord_cols + band_cols + weather_cols\n",
    "\n",
    "# Check that all required columns exist in uhi.\n",
    "missing_cols = [col for col in impute_cols if col not in uhi.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"The following columns are missing from the DataFrame: {missing_cols}\")\n",
    "\n",
    "# Create a copy of the relevant data for imputation.\n",
    "data_to_impute = uhi[impute_cols].copy()\n",
    "\n",
    "# Initialize the KNNImputer.\n",
    "imputer = KNNImputer(n_neighbors=10, weights='distance')\n",
    "\n",
    "# Fit and transform the data.\n",
    "imputed_array = imputer.fit_transform(data_to_impute)\n",
    "\n",
    "# The imputed_array has the same order as impute_cols.\n",
    "# Extract the imputed weather data columns. They are at the end of the array.\n",
    "weather_start_idx = len(coord_cols) + len(band_cols)\n",
    "imputed_weather = imputed_array[:, weather_start_idx:]\n",
    "\n",
    "uhi[weather_cols] = imputed_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weather_cols:\n",
    "    if col not in submission.columns:\n",
    "        submission[col] = np.nan\n",
    "\n",
    "test_for_impute = submission[impute_cols].copy()\n",
    "\n",
    "# Use the trained imputer to transform the test data.\n",
    "imputed_array = imputer.transform(test_for_impute)\n",
    "\n",
    "# The imputer was trained on data with columns in the order:\n",
    "#   coord_cols + band_cols + weather_cols.\n",
    "# Extract the imputed weather columns (the last len(weather_cols) columns).\n",
    "imputed_weather = imputed_array[:, -len(weather_cols):]\n",
    "\n",
    "# Update the test DataFrame's weather columns with the imputed values.\n",
    "submission[weather_cols] = imputed_weather\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y), and then into training and testing sets\n",
    "X = uhi.drop(columns=['Longitude','Latitude','datetime','UHI Index']).values\n",
    "y = uhi['UHI Index'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_xg(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "#         # 'tree_method': trial.suggest_categorical('tree_method', ['exact', 'approx', 'hist'])\n",
    "#     }\n",
    "    \n",
    "#     model = XGBRegressor(**params, random_state=42, tree_method='exact')\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_xg = optuna.create_study(direction='maximize')  \n",
    "# study_xg.optimize(objective_xg, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_xg.best_params)\n",
    "# print('Best Score:', study_xg.best_value)\n",
    "\n",
    "# best_params_xg = study_xg.best_params\n",
    "\n",
    "# with open(\"xg_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_xg.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_xg.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_lgbm(trial):\n",
    "#     # params = {\n",
    "#     #     'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "#     #     'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#     #     'num_leaves': trial.suggest_int('num_leaves', 10, 150),\n",
    "#     #     'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "#     #     'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "#     #     'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "#     #     'bagging_freq': trial.suggest_int('bagging_freq', 3, 7),\n",
    "#     #     'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),  \n",
    "#     #     'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "#     #     'n_estimators': trial.suggest_int('n_estimators', 100, 1000)  \n",
    "#     # }\n",
    "#     params = {\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-6, 0.5),      \n",
    "#         'max_depth': trial.suggest_int('max_depth', 2, 50),                   \n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 5, 300),                 \n",
    "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 200),       \n",
    "#         'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.1, 1.0),   \n",
    "#         'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),               \n",
    "#         'lambda_l1': trial.suggest_float('lambda_l1', 0, 50),                    \n",
    "#         'lambda_l2': trial.suggest_float('lambda_l2', 0, 50),\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 1500)              \n",
    "#     }\n",
    "\n",
    "\n",
    "#     model = LGBMRegressor(**params, random_state=42, verbose=-1)\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "\n",
    "#     return score\n",
    "\n",
    "# study_lgbm = optuna.create_study(direction='maximize')\n",
    "# study_lgbm.optimize(objective_lgbm, n_trials=1000)\n",
    "\n",
    "# print('Best Hyperparameters:', study_lgbm.best_params)\n",
    "# print('Best Score:', study_lgbm.best_value)\n",
    "\n",
    "# best_params_lgbm = study_lgbm.best_params\n",
    "\n",
    "# with open(\"lgbm_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_lgbm.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_lgbm.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_rf(trial):\n",
    "#     params = {\n",
    "#         'n_estimators' : trial.suggest_int(\"n_estimators\", 100, 2000),\n",
    "#         'max_depth' : trial.suggest_int(\"max_depth\", 5, 30),\n",
    "#         'min_samples_split' : trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "#         'min_samples_leaf' : trial.suggest_int(\"min_samples_leaf\", 2, 20),\n",
    "#         'max_features' : trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "#     }\n",
    "    \n",
    "#     model = RandomForestRegressor(**params, random_state=42, n_jobs=-1)\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_rf = optuna.create_study(direction='maximize')  \n",
    "# study_rf.optimize(objective_rf, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_rf.best_params)\n",
    "# print('Best Score:', study_rf.best_value)\n",
    "\n",
    "# best_params_rf = study_rf.best_params\n",
    "\n",
    "# with open(\"rf_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_rf.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_rf.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_cat(trial):\n",
    "#     params = {\n",
    "#         \"iterations\": trial.suggest_int(\"iterations\", 300, 2000),\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 0.5),\n",
    "#         \"depth\": trial.suggest_int(\"depth\", 4, 12),\n",
    "#         \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-5, 10),\n",
    "#         \"random_strength\": trial.suggest_float(\"random_strength\", 0, 10),\n",
    "#         \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0, 1),\n",
    "#         \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "#         \"loss_function\": \"RMSE\",\n",
    "#         \"eval_metric\": \"RMSE\",\n",
    "#         \"random_seed\": 42,\n",
    "#         \"verbose\": 0\n",
    "#     }\n",
    "    \n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_cat = optuna.create_study(direction='maximize')  \n",
    "# study_cat.optimize(objective_cat, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_cat.best_params)\n",
    "# print('Best Score:', study_cat.best_value)\n",
    "\n",
    "# best_params_cat = study_cat.best_params\n",
    "\n",
    "# with open(\"cat_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_cat.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_cat.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_gbr(trial):\n",
    "#     params = {\n",
    "#         #'loss':trial.suggest_categorical('loss', ['squared_error', 'huber', 'quantile', 'absolute_error']),\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
    "#         'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "#         #'criterion': trial.suggest_categorical('criterion', ['friedman_mse', 'squared_error']),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#     }\n",
    "    \n",
    "#     model = GradientBoostingRegressor(**params, random_state=42, criterion='squared_error')\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_gbr = optuna.create_study(direction='maximize')  \n",
    "# study_gbr.optimize(objective_gbr, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_gbr.best_params)\n",
    "# print('Best Score:', study_gbr.best_value)\n",
    "\n",
    "# best_params_gbr = study_gbr.best_params\n",
    "\n",
    "# with open(\"gbr_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_gbr.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_gbr.best_params}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_hgbr(trial):\n",
    "#     params = {\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n",
    "#         'max_iter': trial.suggest_int('max_iter', 100, 2000),\n",
    "#         'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 10, 200),   \n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 100),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#         'l2_regularization': trial.suggest_loguniform('l2_regularization', 1e-5, 1.0),\n",
    "#         'max_bins': trial.suggest_int('max_bins', 100, 255),\n",
    "#     }\n",
    "    \n",
    "#     model = HistGradientBoostingRegressor(**params, random_state=42, loss='squared_error')\n",
    "#     # model.fit(X_train, y_train)\n",
    "\n",
    "#     # preds = model.predict(X_test)\n",
    "#     # score = r2_score(y_test, preds)\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "#     score = scores.mean()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_hgbr = optuna.create_study(direction='maximize')  \n",
    "# study_hgbr.optimize(objective_hgbr, n_trials=100)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", study_hgbr.best_params)\n",
    "# print('Best Score:', study_hgbr.best_value)\n",
    "\n",
    "# best_params_hgbr = study_hgbr.best_params\n",
    "\n",
    "# with open(\"hgbr_results.txt\", \"a\") as f:\n",
    "#     f.write(f\"Best Score: {study_hgbr.best_value}\\n\")\n",
    "#     f.write(f\"Best Hyperparameters: {study_hgbr.best_params}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xg = {'n_estimators': 527, 'learning_rate': 0.0312788331848764, 'max_depth': 17, 'subsample': 0.748120538929842, 'reg_alpha': 0.001241366749156092, 'reg_lambda': 4.027151002258514}\n",
    "best_params_lgbm = {'learning_rate': 0.049306462164681195, 'max_depth': 12, 'num_leaves': 145, 'min_data_in_leaf': 8, 'feature_fraction': 0.8758609827849215, 'bagging_fraction': 0.24707848190077422, 'bagging_freq': 0, 'lambda_l1': 0.0029913663437004133, 'lambda_l2': 6.191482291982284, 'n_estimators': 1318}\n",
    "best_params_rf = {'n_estimators': 713, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
    "best_params_cat = {'iterations': 1765, 'learning_rate': 0.14385381121279203, 'depth': 9, 'l2_leaf_reg': 5.747968794164383, 'random_strength': 6.851846100297218, 'bagging_temperature': 0.010757024517070014, 'border_count': 245}\n",
    "best_params_gbr = {'learning_rate': 0.02706816297254946, 'n_estimators': 1757, 'subsample': 0.8148385854859647, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_depth': 14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBRegressor(**best_params_xg, random_state=42, tree_method='exact')\n",
    "# model = LGBMRegressor(**best_params_lgbm, random_state=42, verbose=-1)\n",
    "# model = CatBoostRegressor(**best_params_cat, verbose=False) \n",
    "# model = GradientBoostingRegressor(**best_params_gbr, random_state=42, criterion='squared_error')\n",
    "# model = HistGradientBoostingRegressor(**best_params_hgbr, random_state=42, loss='squared_error')\n",
    "# model = RandomForestRegressor(**best_params_rf, random_state=42, n_jobs=-1)\n",
    "estimators = [\n",
    "    ('xgb', XGBRegressor(**best_params_xg, random_state=42, tree_method='exact')),\n",
    "    ('cat', CatBoostRegressor(**best_params_cat, verbose=False)),\n",
    "    ('lgb', LGBMRegressor(**best_params_lgbm, random_state=42, verbose=-1)),\n",
    "    ('gbr', GradientBoostingRegressor(**best_params_gbr, random_state=42, criterion='squared_error')),\n",
    "    # ('hgbr', HistGradientBoostingRegressor(**best_params_hgbr, random_state=42, loss='squared_error'))\n",
    "]\n",
    "model = StackingRegressor(\n",
    "    estimators=estimators, \n",
    "    final_estimator=RandomForestRegressor(**best_params_rf, random_state=42, n_jobs=-1),\n",
    "    # final_estimator=XGBRegressor(**best_params_xg, random_state=42, tree_method='exact'),\n",
    "    # final_estimator=GradientBoostingRegressor(**best_params_gbr, random_state=42, criterion='squared_error'),\n",
    "    cv=10,\n",
    "    passthrough=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(cv=10,\n",
       "                  estimators=[(&#x27;xgb&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learn...\n",
       "                               GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;,\n",
       "                                                         learning_rate=0.02706816297254946,\n",
       "                                                         max_depth=14,\n",
       "                                                         min_samples_leaf=8,\n",
       "                                                         min_samples_split=16,\n",
       "                                                         n_estimators=1757,\n",
       "                                                         random_state=42,\n",
       "                                                         subsample=0.8148385854859647))],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=29,\n",
       "                                                        max_features=&#x27;log2&#x27;,\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=4,\n",
       "                                                        n_estimators=713,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                  passthrough=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.StackingRegressor.html\">?<span>Documentation for StackingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingRegressor(cv=10,\n",
       "                  estimators=[(&#x27;xgb&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learn...\n",
       "                               GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;,\n",
       "                                                         learning_rate=0.02706816297254946,\n",
       "                                                         max_depth=14,\n",
       "                                                         min_samples_leaf=8,\n",
       "                                                         min_samples_split=16,\n",
       "                                                         n_estimators=1757,\n",
       "                                                         random_state=42,\n",
       "                                                         subsample=0.8148385854859647))],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=29,\n",
       "                                                        max_features=&#x27;log2&#x27;,\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=4,\n",
       "                                                        n_estimators=713,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                  passthrough=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.0312788331848764,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=17, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=527, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>cat</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x0000019092DECEC0&gt;</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(bagging_fraction=0.24707848190077422, bagging_freq=0,\n",
       "              feature_fraction=0.8758609827849215,\n",
       "              lambda_l1=0.0029913663437004133, lambda_l2=6.191482291982284,\n",
       "              learning_rate=0.049306462164681195, max_depth=12,\n",
       "              min_data_in_leaf=8, n_estimators=1318, num_leaves=145,\n",
       "              random_state=42, verbose=-1)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gbr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;,\n",
       "                          learning_rate=0.02706816297254946, max_depth=14,\n",
       "                          min_samples_leaf=8, min_samples_split=16,\n",
       "                          n_estimators=1757, random_state=42,\n",
       "                          subsample=0.8148385854859647)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=29, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                      min_samples_split=4, n_estimators=713, n_jobs=-1,\n",
       "                      random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(cv=10,\n",
       "                  estimators=[('xgb',\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learn...\n",
       "                               GradientBoostingRegressor(criterion='squared_error',\n",
       "                                                         learning_rate=0.02706816297254946,\n",
       "                                                         max_depth=14,\n",
       "                                                         min_samples_leaf=8,\n",
       "                                                         min_samples_split=16,\n",
       "                                                         n_estimators=1757,\n",
       "                                                         random_state=42,\n",
       "                                                         subsample=0.8148385854859647))],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=29,\n",
       "                                                        max_features='log2',\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=4,\n",
       "                                                        n_estimators=713,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                  passthrough=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990574961500294"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_predictions = model.predict(X_train)\n",
    "Y_train = y_train.tolist()\n",
    "r2_score(Y_train, insample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7772551322317579"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outsample_predictions = model.predict(X_test)\n",
    "Y_test = y_test.tolist()\n",
    "r2_score(Y_test, outsample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', \n",
    "                   'B07', 'B08', 'B8A', 'B11', 'B12', 'LST', 'is_building', \n",
    "                   'Air Temp at Surface [degC]', 'Relative Humidity [percent]', \n",
    "                   'Avg Wind Speed [m/s]', 'Wind Direction [degrees]', 'Solar Flux [W/m^2]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, if submission originally has more columns, select only the ones used in training:\n",
    "submission_prepared = submission[feature_columns].copy()\n",
    "\n",
    "# Now predict:\n",
    "final_predictions = model.predict(submission_prepared)\n",
    "\n",
    "final_prediction_series = pd.Series(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('Submission_template.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'Longitude':sub['Longitude'].values, 'Latitude':sub['Latitude'].values, 'UHI Index':final_prediction_series.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
